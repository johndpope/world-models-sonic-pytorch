{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries B-VAE from https://arxiv.org/pdf/1804.03599.pdf\n",
    "\n",
    "\n",
    "## Notes\n",
    "\n",
    "If it stalls around loss 60, you might need a smaller batch size, e.g. 8\n",
    "\n",
    "\n",
    "\n",
    "## Log\n",
    "\n",
    "### 20180506\n",
    "Why is this not working? It stalls around loss=60 and just reconstructs the same mean image each time.\n",
    "\n",
    "- batchnorm and pad? no lots of other models use them\n",
    "    - https://github.com/josephsmann/UnsupervisedDeepLearning-Pytorch/blob/jm/udlp/autoencoder/convVAE.py#L19\n",
    "    - https://github.com/taey16/pix2pixBEGAN.pytorch/blob/master/models/BEGAN.py\n",
    "- relu, same\n",
    "- lr - similar to other models\n",
    "- inner params - similar but larger than other working models\n",
    "- batch? Maybe it seems better with a lower batch (e.g. 8 instead of 32)\n",
    "- loss, this seems right\n",
    "    - except some people use a loss balance https://github.com/AppliedDataSciencePartners/WorldModels/blob/master/vae/arch.py#L97\n",
    "        where they multuply reconstruction loss by 10 but i've got ~100 vs ~1e-4 so I don't really need to!\n",
    "        \n",
    "- ok a lower batch size seemed to get it over that initial hump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:17.057256Z",
     "start_time": "2018-05-18T01:44:17.054690Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:17.339920Z",
     "start_time": "2018-05-18T01:44:17.059244Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T00:21:02.585280Z",
     "start_time": "2018-05-06T00:21:02.474215Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:17.710196Z",
     "start_time": "2018-05-18T01:44:17.342006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.utils.data\n",
    "\n",
    "# load as dask array\n",
    "import dask.array as da\n",
    "import dask\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:17.849297Z",
     "start_time": "2018-05-18T01:44:17.712131Z"
    }
   },
   "outputs": [],
   "source": [
    "from vae import VAE6, loss_function_vae\n",
    "from helpers.summarize import TorchSummarizeDf\n",
    "from helpers.dataset import load_cache_data\n",
    "from helpers.samplers import SequenceInChunkSampler\n",
    "from rnn import MDNRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:17.867710Z",
     "start_time": "2018-05-18T01:44:17.851298Z"
    }
   },
   "outputs": [],
   "source": [
    "env_name='sonic256'\n",
    "\n",
    "cuda= torch.cuda.is_available()\n",
    "\n",
    "num_epochs=200\n",
    "image_size=256\n",
    "chunksize=1000\n",
    "batch_size=16\n",
    "action_dim = 12\n",
    "seq_len = 1\n",
    "gamma = 0.25\n",
    "# data_cache_file = '/data/tmp/sonic_vae256.hdf5'\n",
    "data_cache_file = '/data/tmp/sonic_rnn_256_v2.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:17.906204Z",
     "start_time": "2018-05-18T01:44:17.869636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fb9336fe080>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fb9336fe5c0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_train, loader_test = load_cache_data(\n",
    "    basedir='/data/vae', \n",
    "    env_name='sonic256', \n",
    "    data_cache_file=data_cache_file, \n",
    "    image_size=image_size, \n",
    "    chunksize=chunksize, \n",
    "    action_dim=action_dim,\n",
    "    batch_size=batch_size,\n",
    "    seq_len=seq_len\n",
    ")\n",
    "loader_train, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:22.351641Z",
     "start_time": "2018-05-18T01:44:17.908184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.float32, torch.uint8, torch.float32, torch.uint8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.dtype for x in next(iter(loader_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T01:28:34.496506Z",
     "start_time": "2018-05-06T01:28:27.517Z"
    }
   },
   "source": [
    "# View model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:22.818981Z",
     "start_time": "2018-05-18T01:44:22.353608Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vae = VAE6(image_size=image_size, z_dim=128, conv_dim=64, code_dim=4, k_dim=256)\n",
    "if cuda:\n",
    "    vae.cuda()\n",
    "    \n",
    "\n",
    "# vae = VAE3(image_size=image_size, z_dim=8, conv_dim=64, code_dim=32, k_dim=512)\n",
    "# if cuda:\n",
    "#     vae.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:32:56.852590Z",
     "start_time": "2018-05-18T01:32:56.811296Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T22:44:19.410808Z",
     "start_time": "2018-05-15T22:44:18.909175Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:22.834165Z",
     "start_time": "2018-05-18T01:44:22.821037Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Resume?\n",
    "NAME='VAE6_6_256im_512z_CVAE'\n",
    "save_file = f'./models/{NAME}_state_dict.pkl'\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    vae.load_state_dict(state_dict)\n",
    "    print(f'loaded {save_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T00:26:31.790320Z",
     "start_time": "2018-05-11T00:26:27.982889Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:23.022751Z",
     "start_time": "2018-05-18T01:44:22.836032Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "(tensor(1.00000e+05 *\n",
      "       [ 2.4467], device='cuda:0'), tensor(1.00000e-02 *\n",
      "       [ 8.5461], device='cuda:0'))\n",
      "Total parameters 21479227\n",
      "Total trainable parameters 21479227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>nb_params</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encoder.0</td>\n",
       "      <td>BasicConv2d</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>[(-1, 64, 256, 256)]</td>\n",
       "      <td>1920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>encoder.1</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 64, 256, 256)]</td>\n",
       "      <td>[(-1, 128, 128, 128)]</td>\n",
       "      <td>165340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>encoder.2</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 128, 128, 128)]</td>\n",
       "      <td>[(-1, 192, 64, 64)]</td>\n",
       "      <td>499000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>encoder.3</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 192, 64, 64)]</td>\n",
       "      <td>[(-1, 256, 32, 32)]</td>\n",
       "      <td>1005460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>encoder.4</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 256, 32, 32)]</td>\n",
       "      <td>[(-1, 320, 16, 16)]</td>\n",
       "      <td>1684720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>encoder.5</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 320, 16, 16)]</td>\n",
       "      <td>[(-1, 384, 8, 8)]</td>\n",
       "      <td>2536780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>encoder.6</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 384, 8, 8)]</td>\n",
       "      <td>[(-1, 448, 4, 4)]</td>\n",
       "      <td>3561640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>encoder.7</td>\n",
       "      <td>BasicConv2d</td>\n",
       "      <td>[(-1, 448, 4, 4)]</td>\n",
       "      <td>[(-1, 128, 4, 4)]</td>\n",
       "      <td>57728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>mu</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2048)]</td>\n",
       "      <td>[(-1, 256)]</td>\n",
       "      <td>524544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>logvar</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2048)]</td>\n",
       "      <td>[(-1, 256)]</td>\n",
       "      <td>524544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>z</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 256)]</td>\n",
       "      <td>[(-1, 2048)]</td>\n",
       "      <td>526336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>decoder.0</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 128, 4, 4)]</td>\n",
       "      <td>[(-1, 448, 4, 4)]</td>\n",
       "      <td>328504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>decoder.1</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 448, 4, 4)]</td>\n",
       "      <td>[(-1, 384, 8, 8)]</td>\n",
       "      <td>3726340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>decoder.2</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 384, 8, 8)]</td>\n",
       "      <td>[(-1, 320, 16, 16)]</td>\n",
       "      <td>2676136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>decoder.3</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 320, 16, 16)]</td>\n",
       "      <td>[(-1, 256, 32, 32)]</td>\n",
       "      <td>1798732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>decoder.4</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 256, 32, 32)]</td>\n",
       "      <td>[(-1, 192, 64, 64)]</td>\n",
       "      <td>1094128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>decoder.5</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 192, 64, 64)]</td>\n",
       "      <td>[(-1, 128, 128, 128)]</td>\n",
       "      <td>562324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>decoder.6</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 128, 128, 128)]</td>\n",
       "      <td>[(-1, 64, 256, 256)]</td>\n",
       "      <td>203320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>decoder.7</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[(-1, 64, 256, 256)]</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>1731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name    class_name            input_shape           output_shape  \\\n",
       "4    encoder.0   BasicConv2d    [(-1, 3, 256, 256)]   [(-1, 64, 256, 256)]   \n",
       "42   encoder.1    ConvBlock5   [(-1, 64, 256, 256)]  [(-1, 128, 128, 128)]   \n",
       "80   encoder.2    ConvBlock5  [(-1, 128, 128, 128)]    [(-1, 192, 64, 64)]   \n",
       "118  encoder.3    ConvBlock5    [(-1, 192, 64, 64)]    [(-1, 256, 32, 32)]   \n",
       "156  encoder.4    ConvBlock5    [(-1, 256, 32, 32)]    [(-1, 320, 16, 16)]   \n",
       "194  encoder.5    ConvBlock5    [(-1, 320, 16, 16)]      [(-1, 384, 8, 8)]   \n",
       "232  encoder.6    ConvBlock5      [(-1, 384, 8, 8)]      [(-1, 448, 4, 4)]   \n",
       "236  encoder.7   BasicConv2d      [(-1, 448, 4, 4)]      [(-1, 128, 4, 4)]   \n",
       "237         mu        Linear           [(-1, 2048)]            [(-1, 256)]   \n",
       "238     logvar        Linear           [(-1, 2048)]            [(-1, 256)]   \n",
       "239          z        Linear            [(-1, 256)]           [(-1, 2048)]   \n",
       "277  decoder.0  DeconvBlock5      [(-1, 128, 4, 4)]      [(-1, 448, 4, 4)]   \n",
       "315  decoder.1  DeconvBlock5      [(-1, 448, 4, 4)]      [(-1, 384, 8, 8)]   \n",
       "353  decoder.2  DeconvBlock5      [(-1, 384, 8, 8)]    [(-1, 320, 16, 16)]   \n",
       "391  decoder.3  DeconvBlock5    [(-1, 320, 16, 16)]    [(-1, 256, 32, 32)]   \n",
       "429  decoder.4  DeconvBlock5    [(-1, 256, 32, 32)]    [(-1, 192, 64, 64)]   \n",
       "467  decoder.5  DeconvBlock5    [(-1, 192, 64, 64)]  [(-1, 128, 128, 128)]   \n",
       "505  decoder.6  DeconvBlock5  [(-1, 128, 128, 128)]   [(-1, 64, 256, 256)]   \n",
       "506  decoder.7        Conv2d   [(-1, 64, 256, 256)]    [(-1, 3, 256, 256)]   \n",
       "507    sigmoid       Sigmoid    [(-1, 3, 256, 256)]    [(-1, 3, 256, 256)]   \n",
       "\n",
       "     nb_params  level  \n",
       "4         1920      1  \n",
       "42      165340      1  \n",
       "80      499000      1  \n",
       "118    1005460      1  \n",
       "156    1684720      1  \n",
       "194    2536780      1  \n",
       "232    3561640      1  \n",
       "236      57728      1  \n",
       "237     524544      0  \n",
       "238     524544      0  \n",
       "239     526336      0  \n",
       "277     328504      1  \n",
       "315    3726340      1  \n",
       "353    2676136      1  \n",
       "391    1798732      1  \n",
       "429    1094128      1  \n",
       "467     562324      1  \n",
       "505     203320      1  \n",
       "506       1731      1  \n",
       "507          0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.randn(image_size, image_size, 3)\n",
    "gpu_img = Variable(torch.from_numpy(img[np.newaxis].transpose(0, 3, 1, 2))).float()\n",
    "if cuda:\n",
    "    gpu_img = gpu_img.cuda()\n",
    "with TorchSummarizeDf(vae) as tdf:\n",
    "    x, mu, logvar = vae.forward(gpu_img)\n",
    "    print(x.size())\n",
    "    print(loss_function_vae(x, gpu_img, mu, logvar))\n",
    "    x = x.data.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "    df = tdf.make_df()\n",
    "    \n",
    "df[df.level<2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:23.042512Z",
     "start_time": "2018-05-18T01:44:23.024743Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def train(loader, net, optimizer, loss_function_vae, test=False, cuda=True):\n",
    "    if test:\n",
    "        net.eval()\n",
    "    else:\n",
    "        net.train()\n",
    "    info = collections.defaultdict(list)\n",
    "    \n",
    "    with tqdm(total=len(loader)*loader.batch_size, mininterval=0.5, desc='test' if test else 'training') as prog:\n",
    "        for i, (observations, actions, rewards, dones) in enumerate(loader):\n",
    "            x = Variable(observations.transpose(1,3))\n",
    "            if cuda:\n",
    "                x=x.cuda()\n",
    "            y, mu, logvar = vae.forward(x)\n",
    "            loss_recon, loss_KLD = loss_function_vae(y, x, mu, logvar)\n",
    "            loss = loss_recon + gamma * torch.abs(loss_KLD-C)\n",
    "            loss = loss.mean() # mean along the batches\n",
    "            \n",
    "            info['loss'].append(loss.cpu().data.item())\n",
    "            info['loss_recon'].append(loss_recon.mean().cpu().data.item())\n",
    "            info['loss_KLD'].append(loss_KLD.mean().cpu().data.item())\n",
    "            \n",
    "            if not test:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            prog.update(loader.batch_size)\n",
    "            prog.desc='loss={loss:2.2f} [ {loss_recon:2.2f} + {rhs:2.2f}={loss_recon:2.2f} + {gamma}*|{loss_KLD:2.2f} - {C}| ]'.format(\n",
    "                loss=np.mean(info['loss']),\n",
    "                loss_recon=np.mean(info['loss_recon']),\n",
    "                gamma=gamma,\n",
    "                C=C,\n",
    "                loss_KLD=np.mean(info['loss_KLD']),\n",
    "                rhs = gamma*np.abs(np.mean(info['loss_KLD'])-C)\n",
    "            )\n",
    "            if i==100:\n",
    "                print(prog.desc)\n",
    "        print(prog.desc)\n",
    "        prog.close()\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:19:34.864488Z",
     "start_time": "2018-05-11T02:19:34.827707Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:23.059534Z",
     "start_time": "2018-05-18T01:44:23.044450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "def plot_results(loader=loader_test, n=2, epoch=0):\n",
    "    x, actions, rewars, dones = next(iter(loader))\n",
    "\n",
    "    X = Variable(x).transpose(1,3).contiguous()\n",
    "    if cuda:\n",
    "        X = X.cuda()\n",
    "    Y, mu, logvar = vae.forward(X)\n",
    "    loss_recon, loss_KLD = loss_function_vae(Y, X, mu, logvar)\n",
    "    loss = loss_recon + gamma * torch.abs(loss_KLD-C)\n",
    "\n",
    "    y=Y.cpu().data.transpose(1,3).numpy()\n",
    "    for i in range(n):\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('original')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(x[i].numpy())\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(y[i])\n",
    "        plt.axis('off')\n",
    "        plt.title('reconstructed')\n",
    "\n",
    "        plt.suptitle('epoch {}, index {}, loss {:2.4f}'.format(epoch, i, loss[i].cpu().data.numpy()))\n",
    "        plt.show()\n",
    "        \n",
    "    del y\n",
    "    del Y\n",
    "    del X\n",
    "    del x\n",
    "    del mu\n",
    "    del logvar\n",
    "    del loss\n",
    "        \n",
    "# plot_results(loader=loader_test, n=2, epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:23.075826Z",
     "start_time": "2018-05-18T01:44:23.061168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "optimizer = optim.Adam(vae.parameters(), lr=3e-4)\n",
    "import torch.optim.lr_scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:23.090396Z",
     "start_time": "2018-05-18T01:44:23.077495Z"
    }
   },
   "outputs": [],
   "source": [
    "histories=[]\n",
    "C = 0\n",
    "C_epoch_inc = 10 # How much to increase C by each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.318259Z",
     "start_time": "2018-05-18T01:44:23.092164Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362c3d00563044de8dac9021093c5048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='training', max=19200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fbf3554ca1c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minfo_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-819de06da97a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader, net, optimizer, loss_function_vae, test, cuda)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs): \n",
    "    info = train(loader_train, vae, optimizer, loss_function_vae, test=False, cuda=True)\n",
    "    info_val = train(loader_test, vae, optimizer, loss_function_vae, test=True, cuda=True)\n",
    "    scheduler.step(np.mean(info_val['loss']))\n",
    "    \n",
    "    C += C_epoch_inc\n",
    "    print('Epoch {}, loss={:2.4f}, loss_val={:2.4f}'.format(epoch, np.mean(info['loss']), np.mean(info_val['loss'])))\n",
    "    \n",
    "    history = {k+'_val':np.mean(v) for k,v in info_val.items()}\n",
    "    history.update({k:np.mean(v) for k,v in info.items()})\n",
    "    histories.append(history)\n",
    "    \n",
    "    plot_results(loader=loader_test, n=4, epoch=epoch)\n",
    "    torch.save(vae.state_dict(), f'./models/{NAME}_{epoch}_state_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T02:53:25.126104Z",
     "start_time": "2018-05-16T02:53:25.105845Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le=1e-4... no diff\n",
    "- Epoch 0, C=100  \n",
    "    - loss=2770.8355, loss_val=3994.2864 \n",
    "    - loss=4080.66=3783.20 + 297.46=3783.20 + 1*|397.46 - 100| \n",
    "\n",
    "lr=1e-3\n",
    "- Epoch 0, C=100  \n",
    "    - loss=2893, loss_val ~3000\n",
    "    - loss=2919.68=2674.58 + 245.09=2674.58 + 1*|345.09 - 100|\n",
    "    \n",
    "lr=1e-3\n",
    "- Epoch 0, C=400  \n",
    "    - loss=3921.11 [ 3887.67 + 28.48=3887.67 + 1*|428.48 - 400| ]\n",
    "    - loss=2560.1797, loss_val=3921.1070\n",
    "- Epoch 1,  C=600\n",
    "    - loss=2383.9083, loss_val=3785.8459\n",
    "    - loss=2801.65 [ 2789.71 + 6.43=2789.71 + 1*|606.43 - 600| ]\n",
    "    - loss=3785.85 [ 3771.32 + 3.96=3771.32 + 1*|603.96 - 600| ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.319165Z",
     "start_time": "2018-05-18T01:44:06.152Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_history = pd.DataFrame(histories)\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.320293Z",
     "start_time": "2018-05-18T01:44:06.154Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), f'./models/{NAME}_state_dict.pkl')\n",
    "torch.save(vae, f'./models/{NAME}.pkl')\n",
    "df_history.to_csv(f'./models/{NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.321380Z",
     "start_time": "2018-05-18T01:44:06.156Z"
    }
   },
   "outputs": [],
   "source": [
    "f'./models/{NAME}_state_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.322369Z",
     "start_time": "2018-05-18T01:44:06.159Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_csv(f'./models/{NAME}.csv').to_dict('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.323218Z",
     "start_time": "2018-05-18T01:44:06.160Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "plot_results(loader=loader_test, n=5, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.324260Z",
     "start_time": "2018-05-18T01:44:06.162Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(loader=loader_train, n=6, epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.325225Z",
     "start_time": "2018-05-18T01:44:06.164Z"
    }
   },
   "outputs": [],
   "source": [
    "%time x=data_test[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:44:40.326151Z",
     "start_time": "2018-05-18T01:44:06.166Z"
    }
   },
   "outputs": [],
   "source": [
    "# DEBUG check chunk size\n",
    "# should be less than 1e9\n",
    "# should take more than 100ms, less than 1s\n",
    "import itertools\n",
    "x=data_train\n",
    "shapes = list(itertools.product(*x.chunks))\n",
    "nbytes = [x.dtype.itemsize * np.prod(shape) for shape in shapes]\n",
    "assert nbytes[0]<1e9\n",
    "nbytes[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
