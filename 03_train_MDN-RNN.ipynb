{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:16:12.961239Z",
     "start_time": "2018-05-10T15:16:12.955191Z"
    }
   },
   "source": [
    "TODO \n",
    "- [x] use pytorch dists to samples and get density in order to make loss\n",
    "- [ ] check equations\n",
    "- [ ] check loss should be negative\n",
    "- make mdrnn just output sigma, mu, pi. We don't need the hidden input?\n",
    "- [x] train\n",
    "    - [ ] mix up multiple batches?\n",
    "    - [ ] make sure it's learning\n",
    "    - [x] plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:44.017936Z",
     "start_time": "2018-05-11T13:34:43.727286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:44.563554Z",
     "start_time": "2018-05-11T13:34:44.021016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.utils.data\n",
    "\n",
    "# load as dask array\n",
    "import dask.array as da\n",
    "import dask\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:44.787299Z",
     "start_time": "2018-05-11T13:34:44.571195Z"
    }
   },
   "outputs": [],
   "source": [
    "from vae import VAE, loss_function\n",
    "from helpers.summarize import TorchSummarizeDf\n",
    "from helpers.dataset import NumpyDataset, TQDMDaskProgressBar, load_npzs\n",
    "from rnn import MDNRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T12:17:19.585326Z",
     "start_time": "2018-05-09T12:17:19.580159Z"
    }
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:44.814235Z",
     "start_time": "2018-05-11T13:34:44.789915Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda= torch.cuda.is_available()\n",
    "env_name='sonic'\n",
    "\n",
    "num_epochs=200\n",
    "batch_size = 8\n",
    "seq_len = 6\n",
    "\n",
    "image_size=128\n",
    "action_dim = 12\n",
    "chunksize=1000\n",
    "\n",
    "data_cache_file = '/tmp/sonic_rnn.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:51.065009Z",
     "start_time": "2018-05-11T13:34:44.817082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/VAE_2xv5_state_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load VAE\n",
    "vae = VAE(image_size=128, z_dim=32, conv_dim=64, code_dim=16, k_dim=128)\n",
    "if cuda:\n",
    "    vae = vae.cuda()\n",
    "# # Resume?\n",
    "NAME='VAE_2xv5'\n",
    "save_file = f'./models/{NAME}_state_dict.pkl'\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    vae.load_state_dict(state_dict)\n",
    "    print(f'loaded {save_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:51.088694Z",
     "start_time": "2018-05-11T13:34:51.067579Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Test VAE\n",
    "# # load\n",
    "# data_cache_file = '/tmp/sonic_vae2.hdf5'\n",
    "# data = da.from_array(h5py.File(data_cache_file, mode='r')['x'], chunks=(2000, 128, 128, 3))\n",
    "# data\n",
    "# data_split = int(len(data)*0.8)\n",
    "# data_train = data[:data_split]\n",
    "# data_test = data[data_split:]\n",
    "# data_train, data_test\n",
    "\n",
    "   \n",
    "# dataset_train = NumpyDataset(data_train)\n",
    "# loader_train = torch.utils.data.DataLoader(dataset_train, pin_memory=True, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# dataset_test = NumpyDataset(data_test)\n",
    "# loader_test = torch.utils.data.DataLoader(dataset_test, pin_memory=True, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# dataset_train, loader_train\n",
    "\n",
    "# # Plot reconstructions\n",
    "# def plot_results(loader=loader_test, n=2, epoch=0):\n",
    "#     x, = next(iter(loader))\n",
    "\n",
    "#     X = Variable(x).cuda().transpose(1,3).contiguous()\n",
    "#     Y, mu, logvar = vae.forward(X)\n",
    "#     loss = loss_function(Y, X, mu, logvar)\n",
    "\n",
    "#     y=Y.cpu().data.transpose(1,3).numpy()\n",
    "#     for i in range(n):\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.title('original')\n",
    "#         plt.imshow(x[i].numpy())\n",
    "\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(y[i])\n",
    "#         plt.title('reconstructed')\n",
    "\n",
    "#         plt.suptitle('epoch {}, index {}, loss {:2.4f}'.format(epoch, i, loss.cpu().data.numpy()))\n",
    "#         plt.show()\n",
    "        \n",
    "# plot_results(loader=loader_test, n=2, epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.614909Z",
     "start_time": "2018-05-11T13:34:51.091023Z"
    }
   },
   "outputs": [],
   "source": [
    "# load as dask array\n",
    "filenames = sorted(glob.glob('./data/vae/obs_data_' + env_name + '_*.npz'))\n",
    "filenames_actions = sorted(glob.glob('./data/vae/action_data_' + env_name + '_*.npz'))\n",
    "\n",
    "if not os.path.isfile(data_cache_file):\n",
    "    data_train = load_npzs(filenames, shuffle=False)\n",
    "    print(data_train)\n",
    "    with TQDMDaskProgressBar():\n",
    "        da.to_hdf5(data_cache_file, '/x', data_train)\n",
    "       \n",
    "    # clear mem\n",
    "    del data_train \n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    y_train = load_npzs(filenames_actions, shuffle=False)\n",
    "    print(y_train)\n",
    "    with TQDMDaskProgressBar():\n",
    "        da.to_hdf5(data_cache_file, '/y', y_train)\n",
    "       \n",
    "    # clear mem\n",
    "    del y_train \n",
    "    import gc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.669651Z",
     "start_time": "2018-05-11T13:34:55.617228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4800, 128, 128, 3), (4800, 12))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "data = da.from_array(h5py.File(data_cache_file, mode='r')['x'], chunks=(chunksize, image_size, image_size, 3))\n",
    "actions = da.from_array(h5py.File(data_cache_file, mode='r')['y'], chunks=(chunksize, action_dim))\n",
    "data\n",
    "data_split = int(len(data)*0.8)\n",
    "data_train = data[:data_split]\n",
    "data_test = data[data_split:]\n",
    "actions_train = actions[:data_split]\n",
    "actions_test = actions[data_split:]\n",
    "data_train.shape, actions_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.703187Z",
     "start_time": "2018-05-11T13:34:55.677309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<helpers.dataset.NumpyDataset at 0x7fba1284c438>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fba1284c860>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_train = NumpyDataset(data_train, actions_train)\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, pin_memory=True, shuffle=False, batch_size=batch_size*seq_len)\n",
    "\n",
    "\n",
    "dataset_test = NumpyDataset(data_test, actions_test)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, pin_memory=True, shuffle=False, batch_size=batch_size*seq_len)\n",
    "\n",
    "dataset_train, loader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.733080Z",
     "start_time": "2018-05-11T13:34:55.710493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size*seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:16:21.354529Z",
     "start_time": "2018-05-10T15:16:21.337627Z"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.773609Z",
     "start_time": "2018-05-11T13:34:55.740481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "def plot_results(n=2, epoch=0, figsize=(9,6)):\n",
    "    vae.eval()\n",
    "    mdnrnn.eval()\n",
    "    \n",
    "    observations, actions = next(iter(loader_test))\n",
    "    \n",
    "    X = Variable(observations.transpose(1,3))\n",
    "    if cuda:\n",
    "        X=X.cuda()\n",
    "    Y, mu_vae, logvar = vae.forward(X)\n",
    "    loss_vae = loss_function(Y, X, mu_vae, logvar)\n",
    "    \n",
    "    # TODO do we want to sample in test or training mode?\n",
    "    z_v = vae.sample(mu_vae, logvar)\n",
    "    z_v = z_v.view(batch_size, seq_len, -1)\n",
    "\n",
    "    # Forward\n",
    "    actions_v = Variable(actions).float()\n",
    "    actions_v = actions_v.view(batch_size, seq_len, -1)\n",
    "    if cuda:\n",
    "        z_v=z_v.cuda()\n",
    "        actions_v=actions_v.cuda()\n",
    "    pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "    loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma)\n",
    "    \n",
    "    # TODO tidy the following few lines\n",
    "#     seq_len2 = mu.size(1)\n",
    "    mu = mu.mean(2).view((batch_size*seq_len, mdnrnn.z_dim))\n",
    "    X_pred = vae.decode(mu)\n",
    "    _, channels, height, width = X.size()\n",
    "    X_pred = X_pred.view((batch_size, seq_len, channels, height, width))\n",
    "    X_pred = X_pred[:, -1]\n",
    "    \n",
    "    for i in np.linspace(0,batch_size-2,n):\n",
    "        i=int(i)\n",
    "        y=Y[i].cpu().data.transpose(0,2).numpy()\n",
    "        x_orig = X[i].transpose(0,2).data.cpu().numpy()\n",
    "        x_next = X[i+1].transpose(0,2).data.cpu().numpy()\n",
    "        x_pred = X_pred[i].transpose(0,2).data.cpu().numpy()\n",
    "        loss_vae_i = loss_vae[i].cpu().data.item()\n",
    "        loss_i = loss[i].cpu().data.item()\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('original')\n",
    "        plt.imshow(x_orig)\n",
    "\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(y)\n",
    "        plt.title('reconstructed')\n",
    "           \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(x_next)\n",
    "        plt.title('true next')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(x_pred)\n",
    "        plt.title('pred next')\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.abs(x_orig-x_next))\n",
    "        plt.title('actual changes')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.abs(y[i]-x_pred))\n",
    "        plt.title('predicted changes')\n",
    "\n",
    "        plt.suptitle('epoch {}, index {}, vae_loss {:2.4f}, loss {:2.4f}'.format(epoch, i, loss_vae[i].cpu().data.item(), loss[i].cpu().data.item()))\n",
    "#         plt.subplots_adjust(wspace=-.4, hspace=.1)#, bottom=0.1, right=0.8, top=0.9)\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.800163Z",
     "start_time": "2018-05-11T13:34:55.780999Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:33:04.204827Z",
     "start_time": "2018-05-11T13:32:45.272Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.846588Z",
     "start_time": "2018-05-11T13:34:55.805874Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def train(loader, vae, mdnrnn, optimizer, test=False, cuda=True):\n",
    "    vae.eval()\n",
    "    if test:\n",
    "        mdnrnn.eval()\n",
    "    else:\n",
    "        mdnrnn.train()\n",
    "    info = collections.defaultdict(list)\n",
    "\n",
    "    with tqdm(total=len(loader)*loader.batch_size, mininterval=0.5, desc='test' if test else 'training') as prog:\n",
    "        for i, (observations, actions) in enumerate(loader):\n",
    "            X = Variable(observations.transpose(1,3))\n",
    "            if cuda:\n",
    "                X=X.cuda()\n",
    "            Y, mu_vae, logvar = vae.forward(X)\n",
    "            # TODO do we want to sample in test or training mode?\n",
    "            z_v = vae.sample(mu_vae, logvar)\n",
    "            z_v = z_v.view(batch_size, seq_len, -1)\n",
    "\n",
    "            # Forward\n",
    "            actions_v = Variable(actions).float()\n",
    "            actions_v = actions_v.view(batch_size, seq_len, -1)\n",
    "            if cuda:\n",
    "                z_v=z_v.cuda()\n",
    "                actions_v=actions_v.cuda()\n",
    "            pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "            loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma).mean()\n",
    "            info['loss'].append(loss.cpu().data.numpy())\n",
    "\n",
    "            if not test:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            prog.update(batch_size)\n",
    "            prog.desc='loss={:2.4f}'.format(np.mean(info['loss']))\n",
    "\n",
    "        print('[{}/{}] loss={:2.4f}'.format(i, num_batches*batch_size, np.mean(info['loss'])))\n",
    "        prog.close()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:34:55.949230Z",
     "start_time": "2018-05-11T13:34:55.851671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MDRNN\n",
    "z_dim, action_dim, hidden_size, n_mixture, temp = 128, 12, 512, 10, 0.0\n",
    "\n",
    "\n",
    "mdnrnn = MDNRNN(z_dim, action_dim, hidden_size, n_mixture, temp)\n",
    "\n",
    "if cuda:\n",
    "    mdnrnn = mdnrnn.cuda()\n",
    "\n",
    "optimizer = optim.Adam(mdnrnn.parameters(), lr=1e-4)\n",
    "import torch.optim.lr_scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.939206Z",
     "start_time": "2018-05-11T13:34:55.955004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceca8e1a2cc42b794544602b10c4adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='training', max=4800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-507a401d787d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdnrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minfo_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdnrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f932d4526924>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader, vae, mdnrnn, optimizer, test, cuda)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mz_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mactions_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdnrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "infos=[]\n",
    "for epoch in range(num_epochs):\n",
    "    info = train(loader_train, vae, mdnrnn, optimizer, test=False, cuda=True)\n",
    "\n",
    "    info_val = train(loader_test, vae, mdnrnn, optimizer, test=True, cuda=True)\n",
    "    scheduler.step(np.mean(info_val['loss']))\n",
    "    \n",
    "    print('Epoch {}, loss={:2.4f}, loss_val={:2.4f}'.format(epoch, np.mean(info['loss']), np.mean(info_val['loss'])))\n",
    "    infos.append([info, info_val])\n",
    "    \n",
    "    plot_results(n=2, epoch=epoch)\n",
    "    torch.save(vae.state_dict(), f'./models/{NAME}_{epoch}_state_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.940782Z",
     "start_time": "2018-05-11T13:34:37.704Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_results(n=2, epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:44:27.867207Z",
     "start_time": "2018-05-11T02:44:27.849505Z"
    }
   },
   "source": [
    "loss=-3.7780: 6% 1120/20000 [00:20<05:40, 55.42it/s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG can we replace tf_normal with torch normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.942611Z",
     "start_time": "2018-05-11T13:34:37.705Z"
    }
   },
   "outputs": [],
   "source": [
    "raise Exception('sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.944458Z",
     "start_time": "2018-05-11T13:34:37.707Z"
    }
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "from custom_envs.env import make_env\n",
    "current_env_name= 'sonic'\n",
    "env = make_env(current_env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.946298Z",
     "start_time": "2018-05-11T13:34:37.710Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DEBUG run one train in global scope\n",
    "# env.close()\n",
    "\n",
    "batch_size = 20\n",
    "num_batches = 1000\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# do a rollout\n",
    "actions = []\n",
    "observations = []\n",
    "rewards=[]\n",
    "\n",
    "observation = env.reset()\n",
    "for i in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    actions.append(action)\n",
    "    observations.append(observation)\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "\n",
    "# stack\n",
    "actions = np.stack(actions)\n",
    "observations = np.stack(observations)\n",
    "rewards = np.stack(rewards)\n",
    "#         actions.shape\n",
    "\n",
    "# Run VAE\n",
    "X = Variable(torch.from_numpy(observations)).cuda().transpose(1,3).contiguous()\n",
    "Y, mu, logvar = vae.forward(X)\n",
    "\n",
    "z = vae.sample(mu, logvar).data.cpu().numpy()\n",
    "#         z.shape\n",
    "\n",
    "# Stack into sequences\n",
    "actions = timeseries_to_seq(actions, window=seq_len)\n",
    "z = timeseries_to_seq(z, window=seq_len)\n",
    "\n",
    "# Forward\n",
    "z_v = Variable(torch.from_numpy(z)).cuda()\n",
    "actions_v = Variable(torch.from_numpy(actions.astype(np.uint8))).float().cuda()\n",
    "if cuda:\n",
    "    z_v=z_v.cuda()\n",
    "    actions_v=actions_v.cuda()\n",
    "pi, mean, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "loss = mdnrnn.rnn_loss(z_v, pi, mean, sigma).mean()\n",
    "print(loss)\n",
    "optimizer.zero_grad()\n",
    "# loss.sum().backward()\n",
    "optimizer.step()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.950053Z",
     "start_time": "2018-05-11T13:34:37.713Z"
    }
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-11T13:34:37.711Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Plot reconstructions\n",
    "# def plot_results(n=2, epoch=0, batch_size=6, figsize=(9,6)):\n",
    "#     vae.eval()\n",
    "#     mdnrnn.eval()\n",
    "    \n",
    "#     # do a rollout\n",
    "#     env = make_env('sonic')\n",
    "#     try:\n",
    "#         actions = []\n",
    "#         observations = []\n",
    "#         rewards=[]\n",
    "\n",
    "#         observation = env.reset()\n",
    "#         for i in range(batch_size):\n",
    "#             action = env.action_space.sample()\n",
    "#             observation, reward, done, env_info = env.step(action)\n",
    "#             actions.append(action)\n",
    "#             observations.append(observation)\n",
    "#             rewards.append(reward)\n",
    "#             if done:\n",
    "#                 observation = env.reset()\n",
    "#     except:\n",
    "#         env.close()\n",
    "#         raise\n",
    "#     else:\n",
    "#         env.close()\n",
    "\n",
    "#     # stack\n",
    "#     actions = np.stack(actions)\n",
    "#     observations = np.stack(observations)\n",
    "#     rewards = np.stack(rewards)\n",
    "\n",
    "#     # Run VAE\n",
    "#     X = Variable(torch.from_numpy(observations)).cuda().transpose(1,3).contiguous()\n",
    "#     Y, mu, logvar = vae.forward(X)\n",
    "#     z = vae.sample(mu, logvar).data.cpu().numpy()\n",
    "#     loss_vae = loss_function(Y, X, mu, logvar)\n",
    "\n",
    "#     # Stack into sequences\n",
    "#     # TODO stack as torch vars\n",
    "#     actions = timeseries_to_seq(actions, window=seq_len)\n",
    "#     z = timeseries_to_seq(z, window=seq_len)\n",
    "\n",
    "#     # Forward\n",
    "#     z_v = Variable(torch.from_numpy(z)).cuda()\n",
    "#     actions_v = Variable(torch.from_numpy(actions.astype(np.uint8))).float().cuda()\n",
    "#     if cuda:\n",
    "#         z_v=z_v.cuda()\n",
    "#         actions_v=actions_v.cuda()\n",
    "#     pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "#     loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma)\n",
    "\n",
    "#     y=Y.cpu().data.transpose(1,3).numpy()\n",
    "    \n",
    "#     # TODO tidy the following few lines\n",
    "#     seq_len2 = mu.size(1)\n",
    "#     mu = mu.mean(2).view((batch_size*seq_len2, mdnrnn.z_dim))\n",
    "#     X_pred = vae.decode(mu)\n",
    "#     _, channels, height, width = X.size()\n",
    "#     X_pred = X_pred.view((batch_size, seq_len2, channels, height, width))\n",
    "#     X_pred = X_pred[:, -1]\n",
    "    \n",
    "#     for i in np.linspace(0,batch_size-2,n):\n",
    "#         i=int(i)\n",
    "        \n",
    "        \n",
    "#         x_orig = X[i].transpose(0,2).data.cpu().numpy()\n",
    "#         x_next = X[i+1].transpose(0,2).data.cpu().numpy()\n",
    "#         x_pred = X_pred[i].transpose(0,2).data.cpu().numpy()\n",
    "#         loss_vae_i = loss_vae[i].cpu().data.item()\n",
    "#         loss_i = loss[i].cpu().data.item()\n",
    "        \n",
    "#         plt.figure(figsize=figsize)\n",
    "        \n",
    "#         plt.subplot(2, 3, 1)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.title('original')\n",
    "#         plt.imshow(x_orig)\n",
    "\n",
    "#         plt.subplot(2, 3, 4)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.imshow(y[i])\n",
    "#         plt.title('reconstructed')\n",
    "           \n",
    "#         plt.subplot(2, 3, 2)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.imshow(x_next)\n",
    "#         plt.title('true next')\n",
    "        \n",
    "#         plt.subplot(2, 3, 5)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.imshow(x_pred)\n",
    "#         plt.title('pred next')\n",
    "        \n",
    "#         plt.subplot(2, 3, 3)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.imshow(np.abs(x_orig-x_next))\n",
    "#         plt.title('actual changes')\n",
    "        \n",
    "#         plt.subplot(2, 3, 6)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.imshow(np.abs(y[i]-x_pred))\n",
    "#         plt.title('predicted changes')\n",
    "\n",
    "#         plt.suptitle('epoch {}, index {}, vae_loss {:2.4f}, loss {:2.4f}'.format(epoch, i, loss_vae[i].cpu().data.item(), loss[i].cpu().data.item()))\n",
    "# #         plt.subplots_adjust(wspace=-.4, hspace=.1)#, bottom=0.1, right=0.8, top=0.9)\n",
    "#         plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.952064Z",
     "start_time": "2018-05-11T13:34:37.716Z"
    }
   },
   "outputs": [],
   "source": [
    "# import collections\n",
    "\n",
    "# def train(make_env, vae, mdnrnn, optimizer, test=False, cuda=True, batch_size=30, num_batches=100):\n",
    "#     try:\n",
    "#         env=make_env('sonic')\n",
    "#         vae.eval()\n",
    "#         if test:\n",
    "#             mdnrnn.eval()\n",
    "#         else:\n",
    "#             mdnrnn.train()\n",
    "#         info = collections.defaultdict(list)\n",
    "\n",
    "#         with tqdm(total=num_batches*batch_size, mininterval=0.5, desc='test' if test else 'training') as prog:\n",
    "#             for i in range(num_batches):\n",
    "#                 # do a rollout\n",
    "#                 actions = []\n",
    "#                 observations = []\n",
    "#                 rewards=[]\n",
    "\n",
    "#                 observation = env.reset()\n",
    "#                 for i in range(batch_size):\n",
    "#                     action = env.action_space.sample()\n",
    "#                     observation, reward, done, env_info = env.step(action)\n",
    "#                     actions.append(action)\n",
    "#                     observations.append(observation)\n",
    "#                     rewards.append(reward)\n",
    "#                     if done:\n",
    "#                         observation = env.reset()\n",
    "\n",
    "#                 # stack\n",
    "#                 actions = np.stack(actions)\n",
    "#                 observations = np.stack(observations)\n",
    "#                 rewards = np.stack(rewards)\n",
    "\n",
    "#                 # Run VAE\n",
    "#                 X = Variable(torch.from_numpy(observations)).cuda().transpose(1,3).contiguous()\n",
    "#                 Y, mu, logvar = vae.forward(X)\n",
    "#                 z = vae.sample(mu, logvar).data.cpu().numpy()\n",
    "# #                 vae_loss = loss_function(Y, X, mu, logvar).sum()\n",
    "\n",
    "#                 # Stack into sequences\n",
    "#                 # TODO stack as torch vars\n",
    "#                 actions = timeseries_to_seq(actions, window=seq_len)\n",
    "#                 z = timeseries_to_seq(z, window=seq_len)\n",
    "\n",
    "#                 # Forward\n",
    "#                 z_v = Variable(torch.from_numpy(z))\n",
    "#                 actions_v = Variable(torch.from_numpy(actions.astype(np.uint8))).float()\n",
    "#                 if cuda:\n",
    "#                     z_v=z_v.cuda()\n",
    "#                     actions_v=actions_v.cuda()\n",
    "#                 pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "#                 loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma).mean()\n",
    "#                 info['loss'].append(loss.cpu().data.numpy())\n",
    "\n",
    "#                 if not test:\n",
    "#                     optimizer.zero_grad()\n",
    "#                     loss.backward()\n",
    "#                     optimizer.step()\n",
    "\n",
    "#                 prog.update(batch_size)\n",
    "#                 prog.desc='loss={:2.4f}'.format(np.mean(info['loss']))\n",
    "\n",
    "#             print('[{}/{}] loss={:2.4f}'.format(i, num_batches*batch_size, np.mean(info['loss'])))\n",
    "#             prog.close()\n",
    "#             env.close()\n",
    "#     except:\n",
    "#         env.close()\n",
    "#         raise\n",
    "#     return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T13:36:00.953799Z",
     "start_time": "2018-05-11T13:34:37.718Z"
    }
   },
   "outputs": [],
   "source": [
    "# import collections\n",
    "\n",
    "# def train(make_env, vae, mdnrnn, optimizer, test=False, cuda=True, batch_size=30, num_batches=100):\n",
    "#     try:\n",
    "#         vae.eval()\n",
    "#         if test:\n",
    "#             mdnrnn.eval()\n",
    "#         else:\n",
    "#             mdnrnn.train()\n",
    "#         info = collections.defaultdict(list)\n",
    "\n",
    "#         with tqdm(total=num_batches*batch_size, mininterval=0.5, desc='test' if test else 'training') as prog:\n",
    "#             for i in range(num_batches):\n",
    "#                 # do a rollout\n",
    "#                 actions = []\n",
    "#                 observations = []\n",
    "#                 rewards=[]\n",
    "                \n",
    "#                 for i in range(batch_size):\n",
    "#                     env=make_env('sonic')\n",
    "#                     observation = env.reset()\n",
    "#                     actions.append([])\n",
    "#                     observations.append([])\n",
    "#                     rewards.append([])\n",
    "#                     for j in range(seq_len):\n",
    "#                         action = env.action_space.sample()\n",
    "#                         observation, reward, done, env_info = env.step(action)\n",
    "#                         actions[-1].append(action)\n",
    "#                         observations[-1].append(observation)\n",
    "#                         rewards[-1].append(reward)\n",
    "#                         if done:\n",
    "#                             observation = env.reset()\n",
    "#                     env.close()\n",
    "\n",
    "#                 # stack\n",
    "#                 actions = np.stack(actions)\n",
    "#                 observations = np.stack(observations)\n",
    "#                 rewards = np.stack(rewards)\n",
    "\n",
    "#                 # Run VAE\n",
    "#                 # the VAE expect (batch, channels, height, width) so we need to reshape\n",
    "#                 _, _, width, height,channels = observations.shape\n",
    "#                 X = Variable(torch.from_numpy(observations)).cuda().transpose(2,4).contiguous()\n",
    "#                 X = X.view(batch_size*seq_len, channels, height, width)\n",
    "#                 Y, mu, logvar = vae.forward(X)\n",
    "#                 z_v = vae.sample(mu, logvar)\n",
    "#                 z_v = z_v.view(batch_size, seq_len, -1)\n",
    "                \n",
    "#                 # TODO I should pregenerate the rollouts\n",
    "\n",
    "#                 # Forward\n",
    "#                 actions_v = Variable(torch.from_numpy(actions.astype(np.uint8))).float()\n",
    "#                 if cuda:\n",
    "#                     z_v=z_v.cuda()\n",
    "#                     actions_v=actions_v.cuda()\n",
    "#                 pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "#                 loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma).mean()\n",
    "#                 info['loss'].append(loss.cpu().data.numpy())\n",
    "\n",
    "#                 if not test:\n",
    "#                     optimizer.zero_grad()\n",
    "#                     loss.backward()\n",
    "#                     optimizer.step()\n",
    "\n",
    "#                 prog.update(batch_size)\n",
    "#                 prog.desc='loss={:2.4f}'.format(np.mean(info['loss']))\n",
    "\n",
    "#             print('[{}/{}] loss={:2.4f}'.format(i, num_batches*batch_size, np.mean(info['loss'])))\n",
    "#             prog.close()\n",
    "#             env.close()\n",
    "#     except:\n",
    "#         env.close()\n",
    "#         raise\n",
    "#     return info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
