{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:16:12.961239Z",
     "start_time": "2018-05-10T15:16:12.955191Z"
    }
   },
   "source": [
    "This used latent space of 1024 and hidden of only 512. But it seems to really struggle because of the smaller hidden space.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:05.776523Z",
     "start_time": "2018-05-20T14:13:05.401647Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.300255Z",
     "start_time": "2018-05-20T14:13:05.778336Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/.pyenv/versions/3.5.3/envs/jupyter3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.utils.data\n",
    "\n",
    "# load as dask array\n",
    "import dask.array as da\n",
    "import dask\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:14:12.470435Z",
     "start_time": "2018-05-20T14:14:12.447320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from world_models_sonic.models.vae import VAE6, loss_function_vae\n",
    "from world_models_sonic.helpers.summarize import TorchSummarizeDf\n",
    "from world_models_sonic.helpers.dataset import load_cache_data\n",
    "from world_models_sonic.models.rnn import MDNRNN2\n",
    "from world_models_sonic.models.inverse_model import InverseModel\n",
    "from world_models_sonic.models.world_model import WorldModel\n",
    "from world_models_sonic.custom_envs.wrappers import discrete_actions\n",
    "from world_models_sonic import config\n",
    "len(discrete_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T12:17:19.585326Z",
     "start_time": "2018-05-09T12:17:19.580159Z"
    }
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:14:18.978000Z",
     "start_time": "2018-05-20T14:14:18.959191Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda= torch.cuda.is_available()\n",
    "env_name='sonic256'\n",
    "num_epochs=200\n",
    "batch_size = 1\n",
    "\n",
    "# VAE loss function\n",
    "lambda_vae_kld = 0.25\n",
    "C = 0\n",
    "z_dim = 256 # latent dimensions\n",
    "\n",
    "# RNN\n",
    "action_dim = 10\n",
    "seq_len = 6\n",
    "image_size=256\n",
    "chunksize=seq_len*20\n",
    "\n",
    "\n",
    "\n",
    "# loss function weights\n",
    "lambda_vae = 1/10\n",
    "lambda_finv = 1\n",
    "\n",
    "data_cache_file = os.path.join(config.base_vae_data_dir, 'sonic_rnn_256_v30.hdf5')\n",
    "NAME='RNN_v3b_256im_512z_1512_v4_greenfield'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:15:10.396079Z",
     "start_time": "2018-05-20T14:15:10.262910Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-20T14:15:11.847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zarr.core.Array (40800, 256, 256, 3) uint8 read-only> <zarr.core.Array (40800,) uint8 read-only> <zarr.core.Array (40800,) uint8 read-only> <zarr.core.Array (40800,) float32 read-only>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80c273fe2e94b8d87ef1648fb8d85c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3401), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader_train, loader_test = load_cache_data(\n",
    "    basedir=config.base_vae_data_dir, \n",
    "    env_name=env_name, \n",
    "    data_cache_file=data_cache_file, \n",
    "    image_size=image_size, \n",
    "    chunksize=chunksize, \n",
    "    action_dim=action_dim,\n",
    "    batch_size=batch_size,\n",
    "    seq_len=seq_len\n",
    ")\n",
    "loader_train, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:32:53.531514Z",
     "start_time": "2018-05-17T14:32:53.515001Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.909673Z",
     "start_time": "2018-05-20T14:13:05.117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load VAE\n",
    "# TODO swap z and k dim, since it's inconsistent with other models\n",
    "vae = VAE6(image_size=image_size, z_dim=32, conv_dim=48, code_dim=8, k_dim=z_dim)\n",
    "if cuda:\n",
    "    vae.cuda()\n",
    "    \n",
    "# # Resume\n",
    "\n",
    "# checkpoint_file = './outputs/models/VAE6_6_256im_512z_inception_CVAE_greenfields_state_dict.pkl'\n",
    "# if os.path.isfile(checkpoint_file):\n",
    "#     state_dict = torch.load(checkpoint_file)\n",
    "#     vae.load_state_dict(state_dict)\n",
    "#     print('loaded checkpoint_file {checkpoint_file}'.format(checkpoint_file=checkpoint_file))\n",
    "    \n",
    "save_file = './outputs/models/{NAME}-vae_state_dict.pkl'.format(NAME=NAME)\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    vae.load_state_dict(state_dict)\n",
    "    print('loaded save_file {save_file}'.format(save_file=save_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.911240Z",
     "start_time": "2018-05-20T14:13:05.122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MDRNN\n",
    "action_dim, hidden_size, n_mixture, temp = action_dim, 128, 3, 0.0\n",
    "\n",
    "\n",
    "mdnrnn = MDNRNN2(z_dim, action_dim, hidden_size, n_mixture, temp)\n",
    "\n",
    "if cuda:\n",
    "    mdnrnn = mdnrnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T04:49:38.571596Z",
     "start_time": "2018-05-18T04:49:38.560500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.912387Z",
     "start_time": "2018-05-20T14:13:05.127Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Resume?\n",
    "save_file = './outputs/models/{NAME}-mdnrnn_state_dict.pkl'.format(NAME=NAME)\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    mdnrnn.load_state_dict(state_dict)\n",
    "    print('loaded {save_file}'.format(save_file=save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load inverse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.913433Z",
     "start_time": "2018-05-20T14:13:05.132Z"
    }
   },
   "outputs": [],
   "source": [
    "finv = InverseModel(z_dim, action_dim, hidden_size=256).cuda()\n",
    "\n",
    "# Resume?\n",
    "save_file = './outputs/models/{NAME}-finv_state_dict.pkl'.format(NAME=NAME)\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    finv.load_state_dict(state_dict)\n",
    "    print('loaded {save_file}'.format(save_file=save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T04:30:29.421769Z",
     "start_time": "2018-05-20T04:30:29.142915Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.914625Z",
     "start_time": "2018-05-20T14:13:05.146Z"
    }
   },
   "outputs": [],
   "source": [
    "img = np.random.randn(image_size, image_size, 3)\n",
    "action = Variable(torch.from_numpy(np.random.randint(0,action_dim,(action_dim)))).float().cuda()[np.newaxis]\n",
    "gpu_img = Variable(torch.from_numpy(img[np.newaxis].transpose(0, 3, 1, 2))).float().cuda()\n",
    "if cuda:\n",
    "    gpu_img = gpu_img.cuda()\n",
    "with TorchSummarizeDf(vae) as tdf:\n",
    "    x, mu_vae, logvar_vae = vae.forward(gpu_img)\n",
    "    z = vae.sample(mu_vae, logvar_vae)\n",
    "    df_vae = tdf.make_df()\n",
    "#     loss_recon, loss_KLD = loss_function_vae(Y, x, mu_vae, sigma_vae)\n",
    "#     loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "#     loss_vae = loss_vae.mean() # mean along the batches\n",
    "\n",
    "\n",
    "df_vae[df_vae.level<2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.915767Z",
     "start_time": "2018-05-20T14:13:05.149Z"
    }
   },
   "outputs": [],
   "source": [
    "with TorchSummarizeDf(mdnrnn) as tdf: \n",
    "    pi, mu, sigma, hidden_state = mdnrnn.forward(z.unsqueeze(1).repeat((1,2,1)), action.unsqueeze(1).repeat((1,2,1)))\n",
    "    z_next = mdnrnn.sample(pi, mu, sigma)\n",
    "#     loss_mdn = mdnrnn.rnn_loss(z, pi, mu, sigma).mean()\n",
    "    df_mdnrnn = tdf.make_df()\n",
    "    \n",
    "df_mdnrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.916967Z",
     "start_time": "2018-05-20T14:13:05.152Z"
    }
   },
   "outputs": [],
   "source": [
    "#     loss = loss_mdn + gamma_vae * loss_vae\n",
    "with TorchSummarizeDf(finv) as tdf:\n",
    "    action_pred = finv(z.repeat((1,2,1)), z_next)\n",
    "        \n",
    "    df_finv = tdf.make_df()\n",
    "    \n",
    "del img, action, gpu_img, x, mu, z\n",
    "df_finv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T02:41:36.949930Z",
     "start_time": "2018-05-17T02:02:24.572Z"
    }
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.918199Z",
     "start_time": "2018-05-20T14:13:05.159Z"
    }
   },
   "outputs": [],
   "source": [
    "model = WorldModel(vae, mdnrnn, finv)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T07:14:32.713022Z",
     "start_time": "2018-05-20T07:14:32.694420Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.919589Z",
     "start_time": "2018-05-20T14:13:05.164Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim.lr_scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:16:21.354529Z",
     "start_time": "2018-05-10T15:16:21.337627Z"
    }
   },
   "source": [
    "# Train helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:32:00.560335Z",
     "start_time": "2018-05-18T10:32:00.542900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.920774Z",
     "start_time": "2018-05-20T14:13:05.172Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "def plot_results(loader, n=2, epoch=0, figsize=(9,6)):\n",
    "    vae.eval()\n",
    "    mdnrnn.eval()\n",
    "    \n",
    "    observations, actions, rewars, dones = next(iter(loader))\n",
    "    \n",
    "    X = Variable(observations.transpose(1,3))\n",
    "    _, channels, height, width = X.size()\n",
    "    if cuda:\n",
    "        X=X.cuda()\n",
    "    Y, mu_vae, logvar = vae.forward(X)\n",
    "    loss_recon, loss_KLD = loss_function_vae(Y, X, mu_vae, logvar)\n",
    "    loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "    \n",
    "    # TODO do we want to sample in test or training mode?\n",
    "    z_v = vae.sample(mu_vae, logvar)\n",
    "    \n",
    "    z_v = z_v.view(batch_size, seq_len, -1)\n",
    "    Y = Y.view((batch_size, seq_len, channels, height, width))\n",
    "    X = X.view((batch_size, seq_len, channels, height, width))\n",
    "    loss_vae = loss_vae.view(batch_size, seq_len)\n",
    "    actions = actions.view(batch_size, seq_len, -1)\n",
    "    \n",
    "    # Forward\n",
    "    actions_v = Variable(actions).float()\n",
    "    \n",
    "\n",
    "    if cuda:\n",
    "        z_v=z_v.cuda()\n",
    "        actions_v=actions_v.cuda()\n",
    "    pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "    z_true_next = z_v[:,1:]\n",
    "    loss_mdn_rnn = mdnrnn.rnn_loss(z_true_next, pi[:,:-1], mu[:,:-1], sigma[:,:-1])\n",
    "    \n",
    "    mu2 = mu.mean(2).view((batch_size*seq_len, mdnrnn.z_dim))\n",
    "    X_pred = vae.decode(mu2)\n",
    "    X_pred = X_pred.view((batch_size, seq_len, channels, height, width))\n",
    "     \n",
    "    # Finv forward\n",
    "    z_next_pred = mdnrnn.sample(pi, mu, sigma)\n",
    "    action_pred = finv(z_v[:,1:], z_next_pred[:,:-1])\n",
    "    loss_inv = ((action_pred-actions_v[:,1:])**2).sum(-1)\n",
    "    \n",
    "    loss = loss_vae.mean(1) + loss_mdn_rnn.mean(1) + loss_inv.mean(1)\n",
    "    \n",
    "    for i in np.linspace(0,seq_len-2,n):\n",
    "        batch = np.random.randint(0,batch_size)\n",
    "        i=int(i)\n",
    "        y=Y[batch][i].cpu().data.transpose(0,2).numpy()\n",
    "        x_orig = X[batch][i].transpose(0,2).data.cpu().numpy()\n",
    "        x_next = X[batch][i+1].transpose(0,2).data.cpu().numpy()\n",
    "        x_pred = X_pred[batch][i].transpose(0,2).data.cpu().numpy()\n",
    "        loss_vae_i = loss_vae[batch][i].cpu().data.item()\n",
    "        loss_mdnrnn_i = loss_mdn_rnn[batch][i].cpu().data.item()\n",
    "        loss_inv_i = loss_inv[batch][i].cpu().data.item()\n",
    "        loss_i = loss[batch].cpu().data.item()\n",
    "        \n",
    "        print_array = lambda x:'['+', '.join(['{:2.2f}'.format(n) for n in x.tolist()])+']'\n",
    "        print('action_pred', print_array(action_pred[batch][i].data.cpu().numpy()))\n",
    "        print('action_true', print_array(actions_v[:,1:][batch][i].data.cpu().numpy()))\n",
    "        print('finv loss {:2.4f}'.format(loss_inv_i))\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('original')\n",
    "        plt.imshow(x_orig)\n",
    "\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(y)\n",
    "        plt.title('reconstructed \\nloss_vae={:2.4f}'.format(loss_vae_i))\n",
    "           \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(x_next)\n",
    "        plt.title('true next')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(x_pred)\n",
    "        plt.title('pred next \\nloss_mdnrnn={:2.4f}'.format(loss_mdnrnn_i))\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.abs(x_orig-x_next))\n",
    "        plt.title('actual changes')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.abs(y[i]-x_pred))\n",
    "        plt.title('predicted changes')\n",
    "\n",
    "        plt.suptitle('epoch {}, seq index {}, batch={}. loss {:2.4f}'.format(\n",
    "            epoch, \n",
    "            i,\n",
    "            batch,\n",
    "            loss_i\n",
    "        ))\n",
    "#         plt.subplots_adjust(wspace=-.4, hspace=.1)#, bottom=0.1, right=0.8, top=0.9)\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.922023Z",
     "start_time": "2018-05-20T14:13:05.182Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def train(loader, vae, mdnrnn, optimizer, max_batches=None, test=False, cuda=True, joint_training=False):\n",
    "    vae.eval()\n",
    "    if test:\n",
    "        mdnrnn.eval()\n",
    "    else:\n",
    "        mdnrnn.train()\n",
    "    info = collections.defaultdict(list)\n",
    "    hidden_state = None\n",
    "    if max_batches is None:\n",
    "        max_batches = len(loader)\n",
    "    else:\n",
    "        max_batches = min(max_batches, len(loader))\n",
    "    iterator = iter(loader)\n",
    "\n",
    "    with tqdm(total=max_batches*loader.batch_size, mininterval=0.5, desc='test' if test else 'training') as prog:\n",
    "        for i in range(max_batches):\n",
    "            # the loader batch_size is seq_len*batch_size\n",
    "            # we put it through the VAE as (seq_len*batch_size,...)\n",
    "            # then reshape to (batch_size,seq_len,...) for the mdnrnn\n",
    "            observations, actions, rewards, dones = next(iterator)\n",
    "            X = Variable(observations.transpose(1,3))\n",
    "            if cuda:\n",
    "                X=X.cuda()\n",
    "                \n",
    "            # VAE forward\n",
    "            Y, mu_vae, logvar = vae.forward(X)\n",
    "            \n",
    "            loss_recon, loss_KLD = loss_function_vae(Y, X, mu_vae, logvar)\n",
    "            loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "            loss_vae = loss_vae.mean() # mean along the batches\n",
    "\n",
    "            # MDNRNN Forward\n",
    "            z_v = vae.sample(mu_vae, logvar)\n",
    "            z_v = z_v.view(batch_size, seq_len, -1)\n",
    "            actions_v = Variable(actions).float()\n",
    "            actions_v = actions_v.view(batch_size, seq_len, -1)\n",
    "            if cuda:\n",
    "                z_v=z_v.cuda()\n",
    "                actions_v=actions_v.cuda()\n",
    "            pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "            # We are evaluating how the output distribution for the next step\n",
    "            # matches the real next step. So we have to discard the last step in the \n",
    "            # sequence which has no next step.\n",
    "            z_true_next = z_v[:,1:]\n",
    "            loss_mdn = mdnrnn.rnn_loss(z_true_next, pi[:,:-1], mu[:,:-1], sigma[:,:-1]).mean()\n",
    "#             loss_mdn += 10 # this is to make sure it stays positive\n",
    "            \n",
    "            # Finv forward\n",
    "            z_next_pred = mdnrnn.sample(pi, mu, sigma)\n",
    "            action_pred = finv(z_v[:,1:], z_next_pred[:,:-1])\n",
    "            loss_inv = ((action_pred-actions_v[:,1:])**2).sum(-1)\n",
    "            loss_inv = loss_inv.mean()\n",
    "            \n",
    "            loss = loss_mdn + lambda_finv * loss_inv + lambda_vae * loss_vae\n",
    "\n",
    "            if not test:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Record\n",
    "            info['loss_inv'].append(loss_inv.cpu().data.numpy())\n",
    "            info['loss_mdn'].append(loss_mdn.cpu().data.numpy())\n",
    "            info['loss_vae'].append(loss_vae.cpu().data.numpy())\n",
    "            info['loss_recon'].append(loss_recon.mean().cpu().data.item())\n",
    "            info['loss_KLD'].append(loss_KLD.mean().cpu().data.item())\n",
    "            \n",
    "            prog.update(loader.batch_size)\n",
    "            prog.desc='loss={loss:2.4f}, loss_rnn={loss_mdn:2.4f}, loss_inv= {loss_inv2:2.4f}={lambda_finv}* {loss_inv:2.4f}, loss_vae={loss_vae:2.4f}={lambda_vae:2.4f} * ({loss_recon:2.2f} + {lambda_vae_kld}*|{loss_KLD:2.2f} - {C}|)'.format(\n",
    "                loss=loss.cpu().data.item(),\n",
    "                loss_mdn=np.mean(info['loss_mdn']), \n",
    "                loss_recon=np.mean(info['loss_recon']),\n",
    "                loss_KLD=np.mean(info['loss_KLD']),\n",
    "                loss_vae=lambda_vae*(np.mean(info['loss_recon'])+lambda_vae_kld*(np.mean(info['loss_KLD'])-C)),\n",
    "                loss_inv=np.mean(info['loss_inv']),\n",
    "                loss_inv2=np.mean(info['loss_inv'])*lambda_finv,\n",
    "                lambda_vae_kld=lambda_vae_kld,\n",
    "                lambda_finv=lambda_finv,\n",
    "                lambda_vae=lambda_vae,\n",
    "                C=C\n",
    "            )\n",
    "            if i%400==0:\n",
    "                print('[{}/{}]'.format(i, max_batches), prog.desc)\n",
    "\n",
    "        print(prog.desc)\n",
    "        prog.close()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:24:46.346285Z",
     "start_time": "2018-05-18T10:24:46.328510Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.923046Z",
     "start_time": "2018-05-20T14:13:05.189Z"
    }
   },
   "outputs": [],
   "source": [
    "max_batches=30000//loader_train.batch_size\n",
    "max_batches\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.925146Z",
     "start_time": "2018-05-20T14:13:05.192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load previous history\n",
    "import pandas as pd\n",
    "if os.path.isfile('./outputs/models/{NAME}.csv'.format(NAME=NAME)):\n",
    "    histories = pd.read_csv('./outputs/models/{NAME}.csv'.format(NAME=NAME)).to_dict(orient='records')\n",
    "else:\n",
    "    histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.927126Z",
     "start_time": "2018-05-20T14:13:05.197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Run\n",
    "    info = train(loader_train, vae, mdnrnn, optimizer, max_batches=max_batches, test=False, cuda=True, joint_training=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    info_val = train(loader_test, vae, mdnrnn, optimizer, max_batches=max_batches//6, test=True, cuda=True, joint_training=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Adjust\n",
    "    scheduler.step(np.mean(info_val['loss_mdn']))\n",
    "    \n",
    "    # View\n",
    "    print('Epoch {}, loss={:2.4f}, loss_val={:2.4f}, loss_vae={:2.4f}, loss_vae_val={:2.4f},  loss_finv={:2.4f}, loss_finv_vae={:2.4f}, ,'.format(\n",
    "        epoch, \n",
    "        np.mean(info['loss_mdn']), \n",
    "        np.mean(info_val['loss_mdn']),\n",
    "        np.mean(info['loss_vae']), \n",
    "        np.mean(info_val['loss_vae']),\n",
    "        np.mean(info['loss_finv']),\n",
    "        np.mean(info_val['loss_finv'])\n",
    "    ))\n",
    "    plot_results(loader_test, n=2, epoch=epoch)\n",
    "    \n",
    "    # Record\n",
    "    history = {k+'_val':np.mean(v) for k,v in info_val.items()}\n",
    "    history.update({k:np.mean(v) for k,v in info.items()})\n",
    "    histories.append(history)\n",
    "    \n",
    "    torch.save(mdnrnn.state_dict(), './outputs/models/{NAME}-mdnrnn_{epoch}_state_dict.pkl'.format(NAME=NAME, epoch=epoch))\n",
    "    torch.save(vae.state_dict(), './outputs/models/{NAME}-vae_{epoch}_state_dict.pkl'.format(NAME=NAME, epoch=epoch))\n",
    "    torch.save(finv.state_dict(), './outputs/models/{NAME}-finv_{epoch}_state_dict.pkl'.format(NAME=NAME, epoch=epoch))\n",
    "    \n",
    "    # Tidy\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T10:19:16.603095Z",
     "start_time": "2018-05-20T10:19:16.582601Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.928452Z",
     "start_time": "2018-05-20T14:13:05.203Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_history = pd.DataFrame(histories)\n",
    "df_history.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.929758Z",
     "start_time": "2018-05-20T14:13:05.209Z"
    }
   },
   "outputs": [],
   "source": [
    "df_history[['loss_mdn','loss_mdn_val']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.931044Z",
     "start_time": "2018-05-20T14:13:05.214Z"
    }
   },
   "outputs": [],
   "source": [
    "df_history[['loss_vae','loss_vae_val']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.932271Z",
     "start_time": "2018-05-20T14:13:05.218Z"
    }
   },
   "outputs": [],
   "source": [
    "df_history[['loss_inv','loss_inv_val']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.933485Z",
     "start_time": "2018-05-20T14:13:05.223Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(mdnrnn.state_dict(), './outputs/models/{NAME}-mdnrnn_state_dict.pkl'.format(NAME=NAME))\n",
    "torch.save(vae.state_dict(), './outputs/models/{NAME}-vae_state_dict.pkl'.format(NAME=NAME))\n",
    "torch.save(finv.state_dict(), './outputs/models/{NAME}-finv_state_dict.pkl'.format(NAME=NAME))\n",
    "# df_history.to_csv('./outputs/models/{NAME}.csv'.format(NAME=NAME), index=False)\n",
    "\n",
    "# torch.save(mdnrnn, f'./outputs/models/{NAME}-mdnrnn.pkl')\n",
    "# torch.save(vae, f'./outputs/models/{NAME}-vae')\n",
    "# torch.save(finv.state_dict(), f'./outputs/models/{NAME}-finv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:44:39.903102Z",
     "start_time": "2018-05-18T10:44:39.758988Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.934842Z",
     "start_time": "2018-05-20T14:13:05.229Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(loader_test, n=4, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:27:25.086326Z",
     "start_time": "2018-05-15T01:27:09.991863Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.936219Z",
     "start_time": "2018-05-20T14:13:05.235Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(loader_train, n=4, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.937450Z",
     "start_time": "2018-05-20T14:13:05.241Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:44:27.867207Z",
     "start_time": "2018-05-11T02:44:27.849505Z"
    }
   },
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:13:06.938676Z",
     "start_time": "2018-05-20T14:13:05.250Z"
    }
   },
   "outputs": [],
   "source": [
    "# DEBUG the distributions\n",
    "vae.train()\n",
    "mdnrnn.train()\n",
    "\n",
    "observations, actions, rewards, dones = next(iter(loader_train))\n",
    "\n",
    "X = Variable(observations.transpose(1,3))\n",
    "_, channels, height, width = X.size()\n",
    "if cuda:\n",
    "    X=X.cuda()\n",
    "Y, mu_vae, logvar = vae.forward(X)\n",
    "loss_recon, loss_KLD = loss_function_vae(Y, X, mu_vae, logvar)\n",
    "loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "\n",
    "# TODO do we want to sample in test or training mode?\n",
    "z_v = vae.sample(mu_vae, logvar)\n",
    "\n",
    "z_v = z_v.view(batch_size, seq_len, -1)\n",
    "Y = Y.view((batch_size, seq_len, channels, height, width))\n",
    "X = X.view((batch_size, seq_len, channels, height, width))\n",
    "loss_vae = loss_vae.view(batch_size, seq_len, -1)\n",
    "actions = actions.view(batch_size, seq_len, -1)\n",
    "\n",
    "# Forward\n",
    "actions_v = Variable(actions).float()\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    z_v=z_v.cuda()\n",
    "    actions_v=actions_v.cuda()\n",
    "pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma)\n",
    "\n",
    "# mu = mu.mean(2).view((batch_size*seq_len, mdnrnn.z_dim))\n",
    "# X_pred = vae.decode(mu)\n",
    "# X_pred = X_pred.view((batch_size, seq_len, channels, height, width))\n",
    "\n",
    "\n",
    "mdnrnn.train()\n",
    "\n",
    "zs=mdnrnn.sample(pi, mu, sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "z_v = vae.sample(mu_vae, logvar)\n",
    "plt.hist(z_v.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('z_v')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(zs.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('z_pred')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mu_vae.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('mu_vae')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mu.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('mu')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(logvar.exp().cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('sigma_vae')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(sigma.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('sigma')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T11:06:04.845302Z",
     "start_time": "2018-05-18T11:06:04.824984Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter3",
   "language": "python",
   "name": "jupyter3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "262px",
    "left": "2px",
    "right": "20px",
    "top": "134px",
    "width": "214px"
   },
   "toc_section_display": true,
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
