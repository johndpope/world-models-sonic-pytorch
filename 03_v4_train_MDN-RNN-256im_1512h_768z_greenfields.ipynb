{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:16:12.961239Z",
     "start_time": "2018-05-10T15:16:12.955191Z"
    }
   },
   "source": [
    "This used latent space of 1024 and hidden of only 512. But it seems to really struggle because of the smaller hidden space.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:04.563734Z",
     "start_time": "2018-05-20T14:55:04.308742Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:04.900377Z",
     "start_time": "2018-05-20T14:55:04.565367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/.pyenv/versions/3.5.3/envs/jupyter3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.utils.data\n",
    "\n",
    "# load as dask array\n",
    "import dask.array as da\n",
    "import dask\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:05.294471Z",
     "start_time": "2018-05-20T14:55:04.902778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from world_models_sonic.models.vae import VAE6, loss_function_vae\n",
    "from world_models_sonic.helpers.summarize import TorchSummarizeDf\n",
    "from world_models_sonic.helpers.dataset import load_cache_data\n",
    "from world_models_sonic.models.rnn import MDNRNN2\n",
    "from world_models_sonic.models.inverse_model import InverseModel\n",
    "from world_models_sonic.models.world_model import WorldModel\n",
    "from world_models_sonic.custom_envs.wrappers import discrete_actions\n",
    "from world_models_sonic import config\n",
    "len(discrete_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T12:17:19.585326Z",
     "start_time": "2018-05-09T12:17:19.580159Z"
    }
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:05.318310Z",
     "start_time": "2018-05-20T14:55:05.296282Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda= torch.cuda.is_available()\n",
    "env_name='sonic256'\n",
    "num_epochs=200\n",
    "batch_size = 1\n",
    "\n",
    "# VAE loss function\n",
    "lambda_vae_kld = 0.25\n",
    "C = 0\n",
    "z_dim = 256 # latent dimensions\n",
    "\n",
    "# RNN\n",
    "action_dim = 10\n",
    "seq_len = 6\n",
    "image_size=256\n",
    "chunksize=seq_len*20\n",
    "\n",
    "\n",
    "\n",
    "# loss function weights\n",
    "lambda_vae = 1/10\n",
    "lambda_finv = 1\n",
    "\n",
    "data_cache_file = os.path.join(config.base_vae_data_dir, 'sonic_rnn_256_v30.hdf5')\n",
    "NAME='RNN_v3b_256im_512z_1512_v4_greenfield'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:21:10.117839Z",
     "start_time": "2018-05-20T14:21:10.079729Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:05.345938Z",
     "start_time": "2018-05-20T14:55:05.320090Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.remove(data_cache_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:05.379582Z",
     "start_time": "2018-05-20T14:55:05.347765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache /MLDATA/sonic/vae/sonic_rnn_256_v30.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f41f2f20630>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f41f2f20be0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_train, loader_test = load_cache_data(\n",
    "    basedir=config.base_vae_data_dir, \n",
    "    env_name=env_name, \n",
    "    data_cache_file=data_cache_file, \n",
    "    image_size=image_size, \n",
    "    chunksize=chunksize, \n",
    "    action_dim=action_dim,\n",
    "    batch_size=batch_size,\n",
    "    seq_len=seq_len\n",
    ")\n",
    "loader_train, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:21:32.415832Z",
     "start_time": "2018-05-20T14:21:32.383491Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:08.711823Z",
     "start_time": "2018-05-20T14:55:05.381409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded save_file ./outputs/models/RNN_v3b_256im_512z_1512_v4_greenfield-vae_state_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load VAE\n",
    "# TODO swap z and k dim, since it's inconsistent with other models\n",
    "vae = VAE6(image_size=image_size, z_dim=32, conv_dim=48, code_dim=8, k_dim=z_dim)\n",
    "if cuda:\n",
    "    vae.cuda()\n",
    "    \n",
    "# # Resume\n",
    "\n",
    "# checkpoint_file = './outputs/models/VAE6_6_256im_512z_inception_CVAE_greenfields_state_dict.pkl'\n",
    "# if os.path.isfile(checkpoint_file):\n",
    "#     state_dict = torch.load(checkpoint_file)\n",
    "#     vae.load_state_dict(state_dict)\n",
    "#     print('loaded checkpoint_file {checkpoint_file}'.format(checkpoint_file=checkpoint_file))\n",
    "    \n",
    "save_file = './outputs/models/{NAME}-vae_state_dict.pkl'.format(NAME=NAME)\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    vae.load_state_dict(state_dict)\n",
    "    print('loaded save_file {save_file}'.format(save_file=save_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:08.754770Z",
     "start_time": "2018-05-20T14:55:08.714837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MDRNN\n",
    "action_dim, hidden_size, n_mixture, temp = action_dim, 128, 3, 0.0\n",
    "\n",
    "\n",
    "mdnrnn = MDNRNN2(z_dim, action_dim, hidden_size, n_mixture, temp)\n",
    "\n",
    "if cuda:\n",
    "    mdnrnn = mdnrnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T04:49:38.571596Z",
     "start_time": "2018-05-18T04:49:38.560500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:08.786382Z",
     "start_time": "2018-05-20T14:55:08.757573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./outputs/models/RNN_v3b_256im_512z_1512_v4_greenfield-mdnrnn_state_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# # Resume?\n",
    "save_file = './outputs/models/{NAME}-mdnrnn_state_dict.pkl'.format(NAME=NAME)\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    mdnrnn.load_state_dict(state_dict)\n",
    "    print('loaded {save_file}'.format(save_file=save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load inverse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:08.813471Z",
     "start_time": "2018-05-20T14:55:08.790247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./outputs/models/RNN_v3b_256im_512z_1512_v4_greenfield-finv_state_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "finv = InverseModel(z_dim, action_dim, hidden_size=256).cuda()\n",
    "\n",
    "# Resume?\n",
    "save_file = './outputs/models/{NAME}-finv_state_dict.pkl'.format(NAME=NAME)\n",
    "if os.path.isfile(save_file):\n",
    "    state_dict = torch.load(save_file)\n",
    "    finv.load_state_dict(state_dict)\n",
    "    print('loaded {save_file}'.format(save_file=save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:34:51.792936Z",
     "start_time": "2018-05-20T14:34:51.630994Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.056752Z",
     "start_time": "2018-05-20T14:55:08.815250Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 8909862\n",
      "Total trainable parameters 8909862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>nb_params</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encoder.0</td>\n",
       "      <td>BasicConv2d</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>[(-1, 48, 256, 256)]</td>\n",
       "      <td>1440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>encoder.1</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 48, 256, 256)]</td>\n",
       "      <td>[(-1, 96, 128, 128)]</td>\n",
       "      <td>93213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>encoder.2</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 96, 128, 128)]</td>\n",
       "      <td>[(-1, 144, 64, 64)]</td>\n",
       "      <td>281034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>encoder.3</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 144, 64, 64)]</td>\n",
       "      <td>[(-1, 192, 32, 32)]</td>\n",
       "      <td>566055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>encoder.4</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 192, 32, 32)]</td>\n",
       "      <td>[(-1, 240, 16, 16)]</td>\n",
       "      <td>948276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>encoder.5</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 240, 16, 16)]</td>\n",
       "      <td>[(-1, 288, 8, 8)]</td>\n",
       "      <td>1427697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>encoder.6</td>\n",
       "      <td>ConvBlock5</td>\n",
       "      <td>[(-1, 288, 8, 8)]</td>\n",
       "      <td>[(-1, 32, 8, 8)]</td>\n",
       "      <td>351550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>mu</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2048)]</td>\n",
       "      <td>[(-1, 256)]</td>\n",
       "      <td>524544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>logvar</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2048)]</td>\n",
       "      <td>[(-1, 256)]</td>\n",
       "      <td>524544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>z</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 256)]</td>\n",
       "      <td>[(-1, 2048)]</td>\n",
       "      <td>526336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>decoder.0</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 32, 8, 8)]</td>\n",
       "      <td>[(-1, 288, 8, 8)]</td>\n",
       "      <td>98254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>decoder.1</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 288, 8, 8)]</td>\n",
       "      <td>[(-1, 240, 16, 16)]</td>\n",
       "      <td>1506078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>decoder.2</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 240, 16, 16)]</td>\n",
       "      <td>[(-1, 192, 32, 32)]</td>\n",
       "      <td>1012401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>decoder.3</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 192, 32, 32)]</td>\n",
       "      <td>[(-1, 144, 64, 64)]</td>\n",
       "      <td>615924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>decoder.4</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 144, 64, 64)]</td>\n",
       "      <td>[(-1, 96, 128, 128)]</td>\n",
       "      <td>316647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>decoder.5</td>\n",
       "      <td>DeconvBlock5</td>\n",
       "      <td>[(-1, 96, 128, 128)]</td>\n",
       "      <td>[(-1, 48, 256, 256)]</td>\n",
       "      <td>114570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>decoder.6</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[(-1, 48, 256, 256)]</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>[(-1, 3, 256, 256)]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name    class_name           input_shape          output_shape  \\\n",
       "4    encoder.0   BasicConv2d   [(-1, 3, 256, 256)]  [(-1, 48, 256, 256)]   \n",
       "42   encoder.1    ConvBlock5  [(-1, 48, 256, 256)]  [(-1, 96, 128, 128)]   \n",
       "80   encoder.2    ConvBlock5  [(-1, 96, 128, 128)]   [(-1, 144, 64, 64)]   \n",
       "118  encoder.3    ConvBlock5   [(-1, 144, 64, 64)]   [(-1, 192, 32, 32)]   \n",
       "156  encoder.4    ConvBlock5   [(-1, 192, 32, 32)]   [(-1, 240, 16, 16)]   \n",
       "194  encoder.5    ConvBlock5   [(-1, 240, 16, 16)]     [(-1, 288, 8, 8)]   \n",
       "232  encoder.6    ConvBlock5     [(-1, 288, 8, 8)]      [(-1, 32, 8, 8)]   \n",
       "233         mu        Linear          [(-1, 2048)]           [(-1, 256)]   \n",
       "234     logvar        Linear          [(-1, 2048)]           [(-1, 256)]   \n",
       "235          z        Linear           [(-1, 256)]          [(-1, 2048)]   \n",
       "273  decoder.0  DeconvBlock5      [(-1, 32, 8, 8)]     [(-1, 288, 8, 8)]   \n",
       "311  decoder.1  DeconvBlock5     [(-1, 288, 8, 8)]   [(-1, 240, 16, 16)]   \n",
       "349  decoder.2  DeconvBlock5   [(-1, 240, 16, 16)]   [(-1, 192, 32, 32)]   \n",
       "387  decoder.3  DeconvBlock5   [(-1, 192, 32, 32)]   [(-1, 144, 64, 64)]   \n",
       "425  decoder.4  DeconvBlock5   [(-1, 144, 64, 64)]  [(-1, 96, 128, 128)]   \n",
       "463  decoder.5  DeconvBlock5  [(-1, 96, 128, 128)]  [(-1, 48, 256, 256)]   \n",
       "464  decoder.6        Conv2d  [(-1, 48, 256, 256)]   [(-1, 3, 256, 256)]   \n",
       "465    sigmoid       Sigmoid   [(-1, 3, 256, 256)]   [(-1, 3, 256, 256)]   \n",
       "\n",
       "     nb_params  level  \n",
       "4         1440      1  \n",
       "42       93213      1  \n",
       "80      281034      1  \n",
       "118     566055      1  \n",
       "156     948276      1  \n",
       "194    1427697      1  \n",
       "232     351550      1  \n",
       "233     524544      0  \n",
       "234     524544      0  \n",
       "235     526336      0  \n",
       "273      98254      1  \n",
       "311    1506078      1  \n",
       "349    1012401      1  \n",
       "387     615924      1  \n",
       "425     316647      1  \n",
       "463     114570      1  \n",
       "464       1299      1  \n",
       "465          0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.randn(image_size, image_size, 3)\n",
    "action = np.array(np.random.randint(0,action_dim))[np.newaxis]\n",
    "action = Variable(torch.from_numpy(action)).float().cuda()[np.newaxis]\n",
    "gpu_img = Variable(torch.from_numpy(img[np.newaxis].transpose(0, 3, 1, 2))).float().cuda()\n",
    "if cuda:\n",
    "    gpu_img = gpu_img.cuda()\n",
    "with TorchSummarizeDf(vae) as tdf:\n",
    "    x, mu_vae, logvar_vae = vae.forward(gpu_img)\n",
    "    z = vae.sample(mu_vae, logvar_vae)\n",
    "    df_vae = tdf.make_df()\n",
    "#     loss_recon, loss_KLD = loss_function_vae(Y, x, mu_vae, sigma_vae)\n",
    "#     loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "#     loss_vae = loss_vae.mean() # mean along the batches\n",
    "\n",
    "\n",
    "df_vae[df_vae.level<2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.101006Z",
     "start_time": "2018-05-20T14:55:09.058376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 1778688\n",
      "Total trainable parameters 1778688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>nb_params</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnn</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[[(-1, 2, 266)], [[(-1, 1, 128)], [(-1, 1, 128...</td>\n",
       "      <td>[[(-1, 2, 128)], [[(-1, 1, 128)], [(-1, 1, 128...</td>\n",
       "      <td>202752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ln1</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 128), (-1, 128)]</td>\n",
       "      <td>[(-1, 128), (-1, 128)]</td>\n",
       "      <td>16512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ln2</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 128), (-1, 128)]</td>\n",
       "      <td>[(-1, 640), (-1, 640)]</td>\n",
       "      <td>82560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdn</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 640), (-1, 640)]</td>\n",
       "      <td>[(-1, 2304), (-1, 2304)]</td>\n",
       "      <td>1476864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name class_name                                        input_shape  \\\n",
       "1  rnn       LSTM  [[(-1, 2, 266)], [[(-1, 1, 128)], [(-1, 1, 128...   \n",
       "2  ln1     Linear                             [(-1, 128), (-1, 128)]   \n",
       "3  ln2     Linear                             [(-1, 128), (-1, 128)]   \n",
       "4  mdn     Linear                             [(-1, 640), (-1, 640)]   \n",
       "\n",
       "                                        output_shape  nb_params  level  \n",
       "1  [[(-1, 2, 128)], [[(-1, 1, 128)], [(-1, 1, 128...     202752      0  \n",
       "2                             [(-1, 128), (-1, 128)]      16512      0  \n",
       "3                             [(-1, 640), (-1, 640)]      82560      0  \n",
       "4                           [(-1, 2304), (-1, 2304)]    1476864      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with TorchSummarizeDf(mdnrnn) as tdf: \n",
    "    pi, mu, sigma, hidden_state = mdnrnn.forward(z.unsqueeze(1).repeat((1,2,1)), action.repeat((1,2)))\n",
    "    z_next = mdnrnn.sample(pi, mu, sigma)\n",
    "#     loss_mdn = mdnrnn.rnn_loss(z, pi, mu, sigma).mean()\n",
    "    df_mdnrnn = tdf.make_df()\n",
    "    \n",
    "df_mdnrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.139354Z",
     "start_time": "2018-05-20T14:55:09.103035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 199690\n",
      "Total trainable parameters 199690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>nb_params</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ln1</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2, 512)]</td>\n",
       "      <td>[(-1, 2, 256)]</td>\n",
       "      <td>131328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ln2</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2, 256)]</td>\n",
       "      <td>[(-1, 2, 256)]</td>\n",
       "      <td>65792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ln3</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[(-1, 2, 256)]</td>\n",
       "      <td>[(-1, 2, 10)]</td>\n",
       "      <td>2570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name class_name     input_shape    output_shape  nb_params  level\n",
       "1  ln1     Linear  [(-1, 2, 512)]  [(-1, 2, 256)]     131328      0\n",
       "2  ln2     Linear  [(-1, 2, 256)]  [(-1, 2, 256)]      65792      0\n",
       "3  ln3     Linear  [(-1, 2, 256)]   [(-1, 2, 10)]       2570      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     loss = loss_mdn + gamma_vae * loss_vae\n",
    "with TorchSummarizeDf(finv) as tdf:\n",
    "    action_pred = finv(z.repeat((1,2,1)), z_next)\n",
    "        \n",
    "    df_finv = tdf.make_df()\n",
    "    \n",
    "del img, action, gpu_img, x, mu, z\n",
    "df_finv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.165276Z",
     "start_time": "2018-05-20T14:55:09.141083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  6]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T02:41:36.949930Z",
     "start_time": "2018-05-17T02:02:24.572Z"
    }
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.192479Z",
     "start_time": "2018-05-20T14:55:09.167096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorldModel(\n",
       "  (vae): VAE6(\n",
       "    (logvar): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (z): Linear(in_features=256, out_features=2048, bias=True)\n",
       "    (encoder): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      )\n",
       "      (1): ConvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(48, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(9, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(12, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (conv1): BasicConv2d(\n",
       "          (conv): Conv2d(48, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(18, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(24, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (conv1): BasicConv2d(\n",
       "          (conv): Conv2d(96, 144, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 27, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(27, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(36, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(144, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (conv1): BasicConv2d(\n",
       "          (conv): Conv2d(144, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (4): ConvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(36, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (conv1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 240, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(240, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(45, 60, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(60, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(240, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (conv1): BasicConv2d(\n",
       "          (conv): Conv2d(240, 288, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (6): ConvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(288, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(54, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(72, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(288, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (conv1): BasicConv2d(\n",
       "          (conv): Conv2d(288, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): DeconvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (deconv1): BasicDeConv2d(\n",
       "          (conv): ConvTranspose2d(32, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (1): DeconvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(288, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(54, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(72, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(288, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (deconv1): BasicDeConv2d(\n",
       "          (conv): ConvTranspose2d(288, 240, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (2): DeconvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(240, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(45, 60, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(60, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(240, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (deconv1): BasicDeConv2d(\n",
       "          (conv): ConvTranspose2d(240, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (3): DeconvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(36, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (deconv1): BasicDeConv2d(\n",
       "          (conv): ConvTranspose2d(192, 144, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (4): DeconvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 27, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(27, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(36, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(144, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (deconv1): BasicDeConv2d(\n",
       "          (conv): ConvTranspose2d(144, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): DeconvBlock5(\n",
       "        (conv0): InceptionA(\n",
       "          (branch1x1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch5x5_2): BasicConv2d(\n",
       "            (conv): Conv2d(18, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_2): BasicConv2d(\n",
       "            (conv): Conv2d(24, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch3x3dbl_3): BasicConv2d(\n",
       "            (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "          (branch_pool): BasicConv2d(\n",
       "            (conv): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "          )\n",
       "        )\n",
       "        (deconv1): BasicDeConv2d(\n",
       "          (conv): ConvTranspose2d(96, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "        (conv2): BasicConv2d(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.01, inplace)\n",
       "        )\n",
       "      )\n",
       "      (6): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (mdnrnn): MDNRNN2(\n",
       "    (rnn): LSTM(266, 128, batch_first=True)\n",
       "    (ln1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (ln2): Linear(in_features=128, out_features=640, bias=True)\n",
       "    (mdn): Linear(in_features=640, out_features=2304, bias=True)\n",
       "  )\n",
       "  (finv): InverseModel(\n",
       "    (ln1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (ln2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (ln3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WorldModel(vae, mdnrnn, finv)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T07:14:32.713022Z",
     "start_time": "2018-05-20T07:14:32.694420Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.221137Z",
     "start_time": "2018-05-20T14:55:09.194487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch.optim.lr_scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:16:21.354529Z",
     "start_time": "2018-05-10T15:16:21.337627Z"
    }
   },
   "source": [
    "# Train helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:32:00.560335Z",
     "start_time": "2018-05-18T10:32:00.542900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:54.046797Z",
     "start_time": "2018-05-20T14:55:53.994014Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "def plot_results(loader, n=2, epoch=0, figsize=(9,6)):\n",
    "    vae.eval()\n",
    "    mdnrnn.eval()\n",
    "    \n",
    "    observations, actions, rewars, dones = next(iter(loader))\n",
    "    \n",
    "    X = Variable(observations.transpose(1,3))\n",
    "    _, channels, height, width = X.size()\n",
    "    if cuda:\n",
    "        X=X.cuda()\n",
    "    Y, mu_vae, logvar = vae.forward(X)\n",
    "    loss_recon, loss_KLD = loss_function_vae(Y, X, mu_vae, logvar)\n",
    "    loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "    \n",
    "    # TODO do we want to sample in test or training mode?\n",
    "    z_v = vae.sample(mu_vae, logvar)\n",
    "    \n",
    "    z_v = z_v.view(batch_size, seq_len, -1)\n",
    "    Y = Y.view((batch_size, seq_len, channels, height, width))\n",
    "    X = X.view((batch_size, seq_len, channels, height, width))\n",
    "    loss_vae = loss_vae.view(batch_size, seq_len)\n",
    "    actions = actions.view(batch_size, seq_len, -1)\n",
    "    \n",
    "    # Forward\n",
    "    actions_v = Variable(actions).float()\n",
    "    \n",
    "\n",
    "    if cuda:\n",
    "        z_v=z_v.cuda()\n",
    "        actions_v=actions_v.cuda()\n",
    "    pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "    z_true_next = z_v[:,1:]\n",
    "    loss_mdn_rnn = mdnrnn.rnn_loss(z_true_next, pi[:,:-1], mu[:,:-1], sigma[:,:-1])\n",
    "    \n",
    "    mu2 = mu.mean(2).view((batch_size*seq_len, mdnrnn.z_dim))\n",
    "    X_pred = vae.decode(mu2)\n",
    "    X_pred = X_pred.view((batch_size, seq_len, channels, height, width))\n",
    "     \n",
    "    # Finv forward\n",
    "    z_next_pred = mdnrnn.sample(pi, mu, sigma)\n",
    "    action_pred = finv(z_v[:,1:], z_next_pred[:,:-1]).float()\n",
    "    loss_inv = ((action_pred-actions_v[:,1:])**2).sum(-1)\n",
    "    \n",
    "    loss = loss_vae.mean(1) + loss_mdn_rnn.mean(1) + loss_inv.mean(1)\n",
    "    \n",
    "    for i in np.linspace(0,seq_len-2,n):\n",
    "        batch = np.random.randint(0,batch_size)\n",
    "        i=int(i)\n",
    "        y=Y[batch][i].cpu().data.transpose(0,2).numpy()\n",
    "        x_orig = X[batch][i].transpose(0,2).data.cpu().numpy()\n",
    "        x_next = X[batch][i+1].transpose(0,2).data.cpu().numpy()\n",
    "        x_pred = X_pred[batch][i].transpose(0,2).data.cpu().numpy()\n",
    "        loss_vae_i = loss_vae[batch][i].cpu().data.item()\n",
    "        loss_mdnrnn_i = loss_mdn_rnn[batch][i].cpu().data.item()\n",
    "        loss_inv_i = loss_inv[batch][i].cpu().data.item()\n",
    "        loss_i = loss[batch].cpu().data.item()\n",
    "        \n",
    "        print_array = lambda x:'['+', '.join(['{:2.2f}'.format(n) for n in x.tolist()])+']'\n",
    "        print('action_pred', print_array(action_pred[batch][i].data.cpu().numpy()))\n",
    "        print('action_true', print_array(actions_v[:,1:][batch][i].data.cpu().numpy()))\n",
    "        print('finv loss {:2.4f}'.format(loss_inv_i))\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('original')\n",
    "        plt.imshow(x_orig)\n",
    "\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(y)\n",
    "        plt.title('reconstructed \\nloss_vae={:2.4f}'.format(loss_vae_i))\n",
    "           \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(x_next)\n",
    "        plt.title('true next')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(x_pred)\n",
    "        plt.title('pred next \\nloss_mdnrnn={:2.4f}'.format(loss_mdnrnn_i))\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.abs(x_orig-x_next))\n",
    "        plt.title('actual changes')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.abs(y[i]-x_pred))\n",
    "        plt.title('predicted changes')\n",
    "\n",
    "        plt.suptitle('epoch {}, seq index {}, batch={}. loss {:2.4f}'.format(\n",
    "            epoch, \n",
    "            i,\n",
    "            batch,\n",
    "            loss_i\n",
    "        ))\n",
    "#         plt.subplots_adjust(wspace=-.4, hspace=.1)#, bottom=0.1, right=0.8, top=0.9)\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:54.850086Z",
     "start_time": "2018-05-20T14:55:54.793756Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def train(loader, vae, mdnrnn, optimizer, max_batches=None, test=False, cuda=True, joint_training=False):\n",
    "    vae.eval()\n",
    "    if test:\n",
    "        mdnrnn.eval()\n",
    "    else:\n",
    "        mdnrnn.train()\n",
    "    info = collections.defaultdict(list)\n",
    "    hidden_state = None\n",
    "    if max_batches is None:\n",
    "        max_batches = len(loader)\n",
    "    else:\n",
    "        max_batches = min(max_batches, len(loader))\n",
    "    iterator = iter(loader)\n",
    "\n",
    "    with tqdm(total=max_batches*loader.batch_size, mininterval=0.5, desc='test' if test else 'training') as prog:\n",
    "        for i in range(max_batches):\n",
    "            # the loader batch_size is seq_len*batch_size\n",
    "            # we put it through the VAE as (seq_len*batch_size,...)\n",
    "            # then reshape to (batch_size,seq_len,...) for the mdnrnn\n",
    "            observations, actions, rewards, dones = next(iterator)\n",
    "            X = Variable(observations.transpose(1,3))\n",
    "            if cuda:\n",
    "                X=X.cuda()\n",
    "                \n",
    "            # VAE forward\n",
    "            Y, mu_vae, logvar = vae.forward(X)\n",
    "            \n",
    "            loss_recon, loss_KLD = loss_function_vae(Y, X, mu_vae, logvar)\n",
    "            loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "            loss_vae = loss_vae.mean() # mean along the batches\n",
    "\n",
    "            # MDNRNN Forward\n",
    "            z_v = vae.sample(mu_vae, logvar)\n",
    "            z_v = z_v.view(batch_size, seq_len, -1)\n",
    "            actions_v = Variable(actions).float()\n",
    "            actions_v = actions_v.view(batch_size, seq_len)\n",
    "            if cuda:\n",
    "                z_v=z_v.cuda()\n",
    "                actions_v=actions_v.cuda()\n",
    "            pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "            # We are evaluating how the output distribution for the next step\n",
    "            # matches the real next step. So we have to discard the last step in the \n",
    "            # sequence which has no next step.\n",
    "            z_true_next = z_v[:,1:]\n",
    "            loss_mdn = mdnrnn.rnn_loss(z_true_next, pi[:,:-1], mu[:,:-1], sigma[:,:-1]).mean()\n",
    "#             loss_mdn += 10 # this is to make sure it stays positive\n",
    "            \n",
    "            # Finv forward\n",
    "            z_next_pred = mdnrnn.sample(pi, mu, sigma)\n",
    "            action_pred = finv(z_v[:,1:], z_next_pred[:,:-1]).float()\n",
    "            loss_inv = ((action_pred-actions_v[:,1:])**2).sum(-1)\n",
    "            loss_inv = loss_inv.mean()\n",
    "            \n",
    "            loss = loss_mdn + lambda_finv * loss_inv + lambda_vae * loss_vae\n",
    "\n",
    "            if not test:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Record\n",
    "            info['loss_inv'].append(loss_inv.cpu().data.numpy())\n",
    "            info['loss_mdn'].append(loss_mdn.cpu().data.numpy())\n",
    "            info['loss_vae'].append(loss_vae.cpu().data.numpy())\n",
    "            info['loss_recon'].append(loss_recon.mean().cpu().data.item())\n",
    "            info['loss_KLD'].append(loss_KLD.mean().cpu().data.item())\n",
    "            \n",
    "            prog.update(loader.batch_size)\n",
    "            prog.desc='loss={loss:2.4f}, loss_rnn={loss_mdn:2.4f}, loss_inv= {loss_inv2:2.4f}={lambda_finv}* {loss_inv:2.4f}, loss_vae={loss_vae:2.4f}={lambda_vae:2.4f} * ({loss_recon:2.2f} + {lambda_vae_kld}*|{loss_KLD:2.2f} - {C}|)'.format(\n",
    "                loss=loss.cpu().data.item(),\n",
    "                loss_mdn=np.mean(info['loss_mdn']), \n",
    "                loss_recon=np.mean(info['loss_recon']),\n",
    "                loss_KLD=np.mean(info['loss_KLD']),\n",
    "                loss_vae=lambda_vae*(np.mean(info['loss_recon'])+lambda_vae_kld*(np.mean(info['loss_KLD'])-C)),\n",
    "                loss_inv=np.mean(info['loss_inv']),\n",
    "                loss_inv2=np.mean(info['loss_inv'])*lambda_finv,\n",
    "                lambda_vae_kld=lambda_vae_kld,\n",
    "                lambda_finv=lambda_finv,\n",
    "                lambda_vae=lambda_vae,\n",
    "                C=C\n",
    "            )\n",
    "            if i%400==0:\n",
    "                print('[{}/{}]'.format(i, max_batches), prog.desc)\n",
    "\n",
    "        print(prog.desc)\n",
    "        prog.close()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:24:46.346285Z",
     "start_time": "2018-05-18T10:24:46.328510Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:55.471876Z",
     "start_time": "2018-05-20T14:55:55.438142Z"
    }
   },
   "outputs": [],
   "source": [
    "max_batches=30000//loader_train.batch_size\n",
    "max_batches\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:55.671036Z",
     "start_time": "2018-05-20T14:55:55.646752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load previous history\n",
    "import pandas as pd\n",
    "if os.path.isfile('./outputs/models/{NAME}.csv'.format(NAME=NAME)):\n",
    "    histories = pd.read_csv('./outputs/models/{NAME}.csv'.format(NAME=NAME)).to_dict(orient='records')\n",
    "else:\n",
    "    histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T15:04:42.489436Z",
     "start_time": "2018-05-20T14:55:55.808660Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df7f9bf0988496e9537d7dba44662dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='training', max=9600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1600] loss=1952.6956, loss_rnn=17.7542, loss_inv= 81.0000=1* 81.0000, loss_vae=1853.9413=0.1000 * (18533.56 + 0.25*|23.42 - 0|)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/.pyenv/versions/3.5.3/envs/jupyter3/lib/python3.5/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400/1600] loss=37.6252, loss_rnn=17.3391, loss_inv= 62.6334=1* 62.6334, loss_vae=1881.8645=0.1000 * (18813.95 + 0.25*|18.76 - 0|)\n",
      "[800/1600] loss=3073.0403, loss_rnn=16.8948, loss_inv= 53.8302=1* 53.8302, loss_vae=2082.9006=0.1000 * (20826.41 + 0.25*|10.38 - 0|)\n",
      "[1200/1600] loss=36.9435, loss_rnn=16.8100, loss_inv= 52.1041=1* 52.1041, loss_vae=2362.1631=0.1000 * (23619.80 + 0.25*|7.32 - 0|)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Run\n",
    "    info = train(loader_train, vae, mdnrnn, optimizer, max_batches=max_batches, test=False, cuda=True, joint_training=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    info_val = train(loader_test, vae, mdnrnn, optimizer, max_batches=max_batches//6, test=True, cuda=True, joint_training=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Adjust\n",
    "    scheduler.step(np.mean(info_val['loss_mdn']))\n",
    "    \n",
    "    # View\n",
    "    print('Epoch {}, loss={:2.4f}, loss_val={:2.4f}, loss_vae={:2.4f}, loss_vae_val={:2.4f},  loss_finv={:2.4f}, loss_finv_vae={:2.4f}, ,'.format(\n",
    "        epoch, \n",
    "        np.mean(info['loss_mdn']), \n",
    "        np.mean(info_val['loss_mdn']),\n",
    "        np.mean(info['loss_vae']), \n",
    "        np.mean(info_val['loss_vae']),\n",
    "        np.mean(info['loss_finv']),\n",
    "        np.mean(info_val['loss_finv'])\n",
    "    ))\n",
    "    plot_results(loader_test, n=2, epoch=epoch)\n",
    "    \n",
    "    # Record\n",
    "    history = {k+'_val':np.mean(v) for k,v in info_val.items()}\n",
    "    history.update({k:np.mean(v) for k,v in info.items()})\n",
    "    histories.append(history)\n",
    "    \n",
    "    torch.save(mdnrnn.state_dict(), './outputs/models/{NAME}-mdnrnn_{epoch}_state_dict.pkl'.format(NAME=NAME, epoch=epoch))\n",
    "    torch.save(vae.state_dict(), './outputs/models/{NAME}-vae_{epoch}_state_dict.pkl'.format(NAME=NAME, epoch=epoch))\n",
    "    torch.save(finv.state_dict(), './outputs/models/{NAME}-finv_{epoch}_state_dict.pkl'.format(NAME=NAME, epoch=epoch))\n",
    "    \n",
    "    # Tidy\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:51.483133Z",
     "start_time": "2018-05-20T14:55:21.209413Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.687001Z",
     "start_time": "2018-05-20T14:55:04.133Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_history = pd.DataFrame(histories)\n",
    "df_history.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.687960Z",
     "start_time": "2018-05-20T14:55:04.137Z"
    }
   },
   "outputs": [],
   "source": [
    "df_history[['loss_mdn','loss_mdn_val']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.689077Z",
     "start_time": "2018-05-20T14:55:04.140Z"
    }
   },
   "outputs": [],
   "source": [
    "df_history[['loss_vae','loss_vae_val']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.690052Z",
     "start_time": "2018-05-20T14:55:04.143Z"
    }
   },
   "outputs": [],
   "source": [
    "df_history[['loss_inv','loss_inv_val']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.691038Z",
     "start_time": "2018-05-20T14:55:04.146Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(mdnrnn.state_dict(), './outputs/models/{NAME}-mdnrnn_state_dict.pkl'.format(NAME=NAME))\n",
    "torch.save(vae.state_dict(), './outputs/models/{NAME}-vae_state_dict.pkl'.format(NAME=NAME))\n",
    "torch.save(finv.state_dict(), './outputs/models/{NAME}-finv_state_dict.pkl'.format(NAME=NAME))\n",
    "# df_history.to_csv('./outputs/models/{NAME}.csv'.format(NAME=NAME), index=False)\n",
    "\n",
    "# torch.save(mdnrnn, f'./outputs/models/{NAME}-mdnrnn.pkl')\n",
    "# torch.save(vae, f'./outputs/models/{NAME}-vae')\n",
    "# torch.save(finv.state_dict(), f'./outputs/models/{NAME}-finv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T10:44:39.903102Z",
     "start_time": "2018-05-18T10:44:39.758988Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.692044Z",
     "start_time": "2018-05-20T14:55:04.152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(loader_test, n=4, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:27:25.086326Z",
     "start_time": "2018-05-15T01:27:09.991863Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.693043Z",
     "start_time": "2018-05-20T14:55:04.158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(loader_train, n=4, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.694104Z",
     "start_time": "2018-05-20T14:55:04.161Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:44:27.867207Z",
     "start_time": "2018-05-11T02:44:27.849505Z"
    }
   },
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:55:09.695083Z",
     "start_time": "2018-05-20T14:55:04.167Z"
    }
   },
   "outputs": [],
   "source": [
    "# DEBUG the distributions\n",
    "vae.train()\n",
    "mdnrnn.train()\n",
    "\n",
    "observations, actions, rewards, dones = next(iter(loader_train))\n",
    "\n",
    "X = Variable(observations.transpose(1,3))\n",
    "_, channels, height, width = X.size()\n",
    "if cuda:\n",
    "    X=X.cuda()\n",
    "Y, mu_vae, logvar = vae.forward(X)\n",
    "loss_recon, loss_KLD = loss_function_vae(Y, X, mu_vae, logvar)\n",
    "loss_vae = loss_recon + lambda_vae_kld * torch.abs(loss_KLD-C)\n",
    "\n",
    "# TODO do we want to sample in test or training mode?\n",
    "z_v = vae.sample(mu_vae, logvar)\n",
    "\n",
    "z_v = z_v.view(batch_size, seq_len, -1)\n",
    "Y = Y.view((batch_size, seq_len, channels, height, width))\n",
    "X = X.view((batch_size, seq_len, channels, height, width))\n",
    "loss_vae = loss_vae.view(batch_size, seq_len, -1)\n",
    "actions = actions.view(batch_size, seq_len)\n",
    "\n",
    "# Forward\n",
    "actions_v = Variable(actions).float()\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    z_v=z_v.cuda()\n",
    "    actions_v=actions_v.cuda()\n",
    "pi, mu, sigma, hidden_state = mdnrnn.forward(z_v, actions_v)\n",
    "\n",
    "loss = mdnrnn.rnn_loss(z_v, pi, mu, sigma)\n",
    "\n",
    "# mu = mu.mean(2).view((batch_size*seq_len, mdnrnn.z_dim))\n",
    "# X_pred = vae.decode(mu)\n",
    "# X_pred = X_pred.view((batch_size, seq_len, channels, height, width))\n",
    "\n",
    "\n",
    "mdnrnn.train()\n",
    "\n",
    "zs=mdnrnn.sample(pi, mu, sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "z_v = vae.sample(mu_vae, logvar)\n",
    "plt.hist(z_v.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('z_v')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(zs.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('z_pred')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mu_vae.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('mu_vae')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mu.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('mu')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(logvar.exp().cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('sigma_vae')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(sigma.cpu().data.numpy().flatten(), bins=50)\n",
    "plt.title('sigma')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T11:06:04.845302Z",
     "start_time": "2018-05-18T11:06:04.824984Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter3",
   "language": "python",
   "name": "jupyter3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "262px",
    "left": "2px",
    "right": "20px",
    "top": "134px",
    "width": "214px"
   },
   "toc_section_display": true,
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
